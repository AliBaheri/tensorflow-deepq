{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.models import Layer, LSTMLayer, MultiLSTMLayer, SequenceWrapper\n",
    "from tf_rl.controller import DiscreteDeepQ\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind': lambda x: '%.3f' % (x,)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATAPATH = \"/home/sidor/projects/Dali/data/babi/tasks/en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 qa1_single-supporting-fact_train.txt\n",
      "262 qa2_two-supporting-facts_train.txt\n",
      "312 qa3_three-supporting-facts_train.txt\n",
      "120 qa4_two-arg-relations_train.txt\n",
      "367 qa5_three-arg-relations_train.txt\n",
      "245 qa6_yes-no-questions_train.txt\n",
      "346 qa7_counting_train.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(600, 150, 150)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SENTENCE_LEN = 7\n",
    "\n",
    "def extract_sentences(filename):\n",
    "    with open(filename) as f:\n",
    "        res = []\n",
    "        for line in f:\n",
    "            if '?' in line: continue\n",
    "            line = line[:-1].replace('.', ' ')\n",
    "            line = line.split(' ')[1:]\n",
    "            line = [w for w in line if w != '' and w != ' ']\n",
    "            if len(line) == 0 or len(line) > MAX_SENTENCE_LEN: continue\n",
    "            res.append(line)\n",
    "        res = [tuple(s) for s in res]\n",
    "        res = list(set(res))\n",
    "        return res\n",
    "\n",
    "def load_data(datapath, num_tasks, tvt_examples):\n",
    "    tasks = [f for f in listdir(datapath) if f.endswith('_train.txt')]\n",
    "    tasks.sort(key=lambda x: int(x.split('_')[0][2:]))\n",
    "    assert 0 <= num_tasks <= len(tasks)\n",
    "    \n",
    "    ntrain, nvalidate, ntest = tvt_examples\n",
    "    train, validate, test = [], [], []\n",
    "    tasks_processed = 0\n",
    "    for task in tasks:\n",
    "        s = extract_sentences(join(datapath, task))\n",
    "        print(len(s), task)\n",
    "        if len(s) < sum(tvt_examples): \n",
    "            continue\n",
    "        random.shuffle(s)\n",
    "        train.extend(s[:ntrain])\n",
    "        validate.extend(s[ntrain:(ntrain+nvalidate)])\n",
    "        test.extend(s[(ntrain+nvalidate):(ntrain+nvalidate+ntest)])\n",
    "        tasks_processed += 1\n",
    "        if tasks_processed == num_tasks:\n",
    "            break\n",
    "    if tasks_processed < num_tasks:\n",
    "        raise Exception(\"Not enough tasks with sufficient examples\")\n",
    "    for dataset in [train, validate, test]:\n",
    "        random.shuffle(dataset)\n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = load_data(DATAPATH, 5, (120, 30, 30))\n",
    "len(train), len(validate), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sentences = train + test + validate\n",
    "EOS = \"**EOS**\"\n",
    "compute_dict = lambda sentences: list(set(w for s in sentences for w in s)) + [EOS]\n",
    "\n",
    "assert len(compute_dict(train)) >= len(compute_dict(validate)) and \\\n",
    "       len(compute_dict(train)) >= len(compute_dict(test)), \"Words in validate/test do not occur in train set\"\n",
    "dictionary = compute_dict(all_sentences)\n",
    "SEQ_LEN = max(len(s) for s in all_sentences) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def move_element(s, x,y):\n",
    "    indexes = list(range(len(s)))\n",
    "    indexes.remove(x)\n",
    "    new_index = indexes[y]\n",
    "    element = s[x]\n",
    "    v = s[:x] + s[(x+1):]\n",
    "    return v[:new_index] + [element] + v[new_index:]\n",
    "\n",
    "def pad_sentence(sentence):\n",
    "    sentence = list(sentence[:])\n",
    "    while len(sentence) < SEQ_LEN:\n",
    "        sentence.append(EOS)\n",
    "    return sentence\n",
    "\n",
    "class Reshuffling(object):\n",
    "    def __init__(self, sentence, max_len, dictionary, action_type):\n",
    "        assert len(sentence) == max_len\n",
    "        self.max_len = max_len\n",
    "        if action_type == 'swap':\n",
    "            self.actions = list(combinations(range(max_len), 2)) + [\"STOP\"]\n",
    "        elif action_type == 'move':\n",
    "            self.actions = list(product(range(max_len), range(max_len - 1))) + [\"STOP\"]\n",
    "        else:\n",
    "            assert False\n",
    "        self.action_type = action_type\n",
    "        self.num_actions = len(self.actions)\n",
    "        \n",
    "        self.observation_size = max_len\n",
    "        self.goal    = sentence[:]\n",
    "        self.state       = list(sentence[:])\n",
    "        random.shuffle(self.state)\n",
    "        \n",
    "        self.steps       = 0\n",
    "        self.stopped     = False\n",
    "        self.last_objective = self.objective()\n",
    "        \n",
    "    def objective(self):\n",
    "        return sum([1 if a == b else 0 for a, b in zip(self.goal, self.state)])\n",
    "        \n",
    "    def perform_action(self, action_idx):\n",
    "        self.steps += 1\n",
    "        a = self.actions[action_idx]\n",
    "        if a == \"STOP\":\n",
    "            self.stopped = True\n",
    "        elif isinstance(a, tuple) and len(a) == 2:\n",
    "            x, y = a\n",
    "            if self.action_type == 'swap':\n",
    "                self.state[x], self.state[y] = self.state[y], self.state[x]\n",
    "            elif self.action_type == 'move':\n",
    "                self.state = move_element(self.state, x, y)\n",
    "            else:\n",
    "                assert False\n",
    "        else:\n",
    "            assert False\n",
    "            \n",
    "    def observe(self):\n",
    "        if self.stopped:\n",
    "            return None\n",
    "        else:\n",
    "            return np.array([dictionary.index(w) for w in self.state])\n",
    "        \n",
    "    def done(self):\n",
    "        return self.stopped\n",
    "        \n",
    "    def success(self):\n",
    "        return r.stopped and self.objective() == self.max_len\n",
    "    \n",
    "    def collect_reward(self):\n",
    "        if self.stopped:\n",
    "            return 1 if self.objective() == len(self.goal) else 0\n",
    "        else:\n",
    "            obj = self.objective()\n",
    "            reward = obj - self.last_objective \n",
    "            self.last_objective = obj\n",
    "            return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['**EOS**', 'travelled', 'bathroom', '**EOS**', 'to', 'Daniel', 'the'] 1\n",
      "(0, 5)\n",
      "['travelled', 'bathroom', '**EOS**', 'to', 'Daniel', 'the', '**EOS**'] 1\n",
      "['Daniel', 'travelled', 'to', 'the', 'bathroom', '**EOS**', '**EOS**']\n",
      "[15 29 37  7 20 26 37]\n",
      "0\n",
      "0\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "r = Reshuffling(pad_sentence(train[0]), SEQ_LEN, dictionary, action_type='move')\n",
    "print(r.state, r.objective())\n",
    "r.perform_action(5)\n",
    "print(r.actions[5])\n",
    "print(r.state, r.objective())\n",
    "print(r.goal)\n",
    "print(r.observe())\n",
    "print(r.collect_reward())\n",
    "print(r.collect_reward())\n",
    "print(r.success())\n",
    "r.state = r.goal\n",
    "print(r.success())\n",
    "print(r.done())\n",
    "r.perform_action(r.num_actions-1)\n",
    "print(r.done())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NLPDeepQ(DiscreteDeepQ):\n",
    "    def create_observation_variable(self, name):\n",
    "        return tf.placeholder(tf.int32, (SEQ_LEN, None), name=name)\n",
    "\n",
    "    def prepare_observation(self, observation):\n",
    "        return observation[:, np.newaxis]\n",
    "\n",
    "    def batch_samples(self, samples):\n",
    "        # batch states\n",
    "        states         = np.empty(self.observation_size + [len(samples)], dtype=np.int32)\n",
    "        newstates      = np.empty(self.observation_size + [len(samples)], dtype=np.int32)\n",
    "        action_mask    = np.zeros((len(samples), self.num_actions))\n",
    "\n",
    "        newstates_mask = np.empty((len(samples),))\n",
    "        rewards        = np.empty((len(samples),))\n",
    "\n",
    "        for i, (state, action, reward, newstate) in enumerate(samples):\n",
    "            states[:, i] = state\n",
    "            action_mask[i] = 0\n",
    "            action_mask[i][action] = 1\n",
    "            rewards[i] = reward\n",
    "            if newstate is not None:\n",
    "                newstates[:, i] = newstate\n",
    "                newstates_mask[i] = 1\n",
    "            else:\n",
    "                newstates[:, i] = 0\n",
    "                newstates_mask[i] = 0\n",
    "\n",
    "        return states, action_mask, rewards, newstates, newstates_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tf_rl.models import base_name\n",
    "\n",
    "class NLPLSTM(object):\n",
    "    def __init__(self, embedding_size, nsymbols, lstm_hiddens, scope=\"NLPLSTM\", initialize=True):\n",
    "        self.embedding_size, self.nsymbols, self.lstm_hiddens = embedding_size, nsymbols, lstm_hiddens\n",
    "        self.scope = scope\n",
    "        self.embedding, self.lstm = None, None\n",
    "        if initialize:\n",
    "            with tf.variable_scope(self.scope):\n",
    "                embedding_i =  tf.random_uniform_initializer(- 1.0 / math.sqrt(embedding_size), \n",
    "                                                             1.0 / math.sqrt(embedding_size))\n",
    "                self.embedding = tf.get_variable('embedding', (nsymbols, embedding_size), initializer=embedding_i)\n",
    "                self.lstm = MultiLSTMLayer(embedding_size, lstm_hiddens)\n",
    "\n",
    "    def __call__(self, words):\n",
    "        embedded = tf.nn.embedding_lookup(self.embedding, words, name=\"embedded\")\n",
    "        lstm_inputs  = [ embedded[i,:,:] for i in range(embedded.get_shape().as_list()[0])]\n",
    "\n",
    "        rnn_outputs = []\n",
    "        rnn_states = []\n",
    "        batch_size = tf.shape(lstm_inputs[0])[0]\n",
    "        state = self.lstm.initial_state(batch_size)\n",
    "        for input_ in lstm_inputs:\n",
    "            output, state = self.lstm(input_, state)\n",
    "            rnn_outputs.append(output)\n",
    "            rnn_states.append(state)\n",
    "        \n",
    "        return rnn_outputs, rnn_states\n",
    "    \n",
    "    def variables(self):\n",
    "        return [self.embedding] + self.lstm.variables()\n",
    "    \n",
    "    def copy(self, scope=None):\n",
    "        if scope is None:\n",
    "            scope = self.scope + \"_copy\"\n",
    "        res = NLPLSTM(self.embedding_size, self.nsymbols, self.lstm_hiddens, scope=scope, initialize=False)\n",
    "        with tf.variable_scope(scope):\n",
    "            res.embedding = tf.get_variable(base_name(self.embedding), self.embedding.get_shape(),\n",
    "                        initializer=lambda x, dtype=tf.float32: self.embedding.initialized_value())\n",
    "            res.lstm     = self.lstm.copy()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACTION_TYPE='move'\n",
    "r = Reshuffling(pad_sentence(train[0]), SEQ_LEN, dictionary, action_type=ACTION_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "HIDDEN_SIZES   = [100,100,50]\n",
    "NSYMBOLS       = len(dictionary)\n",
    "NACTIONS       = r.num_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.ops.reset_default_graph()\n",
    "if 'session' in globals():\n",
    "    session.close()\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    lstm = NLPLSTM(EMBEDDING_SIZE, NSYMBOLS, HIDDEN_SIZES, scope=\"nlplstm\")\n",
    "    decoder = Layer(HIDDEN_SIZES[-1], NACTIONS, scope=\"decoder\")\n",
    "\n",
    "    brain = SequenceWrapper([\n",
    "        lstm,\n",
    "        lambda x: x[0][-1][-1],\n",
    "        decoder,   \n",
    "    ])\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0005, beta1=0.5)\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
    "\n",
    "    assert r.observation_size == SEQ_LEN\n",
    "\n",
    "    current_controller = NLPDeepQ(r.observation_size, r.num_actions, brain, optimizer, session,\n",
    "                                  discount_rate=0.99, exploration_period=5000, max_experience=20000, \n",
    "                                  store_every_nth=1, train_every_nth=2,\n",
    "                                  target_network_update_rate=0.001,\n",
    "                                  summary_writer=None)\n",
    "\n",
    "    session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_example(sentence, training=True, debug=False):\n",
    "    r = Reshuffling(pad_sentence(sentence), SEQ_LEN, dictionary, action_type=ACTION_TYPE)\n",
    "    state = r.observe()\n",
    "    while not r.done() and r.steps < 15:\n",
    "        r_prev_state = r.state[:]\n",
    "        action = current_controller.action(state, exploration=training)\n",
    "        r.perform_action(action)\n",
    "        reward = r.collect_reward()\n",
    "        if debug: print('%d\\t%s\\t%.1f\\t%s' % (r.steps, r.actions[action], float(reward), r_prev_state))\n",
    "        newstate = r.observe()\n",
    "        if training:\n",
    "            current_controller.store(state, action, reward, newstate)\n",
    "            current_controller.training_step()\n",
    "        state = newstate\n",
    "    return r\n",
    "\n",
    "def accuracy(dataset, seed=None, repeats=1):\n",
    "    if seed: random.seed(seed)\n",
    "    result = 0.0\n",
    "    avg_objective = 0.0\n",
    "    for ex in dataset:\n",
    "        for _ in range(repeats):\n",
    "            r = run_example(ex, training=False, debug=False)\n",
    "            result += 1.0 if r.success() else 0.0\n",
    "            avg_objective += r.objective()\n",
    "    avg_objective /= len(dataset) * repeats\n",
    "    result /= len(dataset) * repeats\n",
    "    if seed: random.seed()\n",
    "    return result, avg_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before epoch 0 => accuracy: 0.0 %, avg_objective: 1.2\n",
      "1\t(2, 2)\t0.0\t['to', 'went', 'Fred', '**EOS**', '**EOS**', 'bedroom', 'the']\n",
      "2\t(2, 2)\t0.0\t['to', 'went', '**EOS**', 'Fred', '**EOS**', 'bedroom', 'the']\n",
      "3\t(2, 2)\t0.0\t['to', 'went', 'Fred', '**EOS**', '**EOS**', 'bedroom', 'the']\n",
      "4\t(2, 2)\t0.0\t['to', 'went', '**EOS**', 'Fred', '**EOS**', 'bedroom', 'the']\n",
      "5\t(2, 2)\t0.0\t['to', 'went', 'Fred', '**EOS**', '**EOS**', 'bedroom', 'the']\n",
      "6\t(2, 2)\t0.0\t['to', 'went', '**EOS**', 'Fred', '**EOS**', 'bedroom', 'the']\n",
      "7\t(2, 2)\t0.0\t['to', 'went', 'Fred', '**EOS**', '**EOS**', 'bedroom', 'the']\n",
      "8\t(2, 2)\t0.0\t['to', 'went', '**EOS**', 'Fred', '**EOS**', 'bedroom', 'the']\n",
      "9\t(2, 2)\t0.0\t['to', 'went', 'Fred', '**EOS**', '**EOS**', 'bedroom', 'the']\n",
      "10\t(2, 2)\t0.0\t['to', 'went', '**EOS**', 'Fred', '**EOS**', 'bedroom', 'the']\n",
      "11\t(2, 2)\t0.0\t['to', 'went', 'Fred', '**EOS**', '**EOS**', 'bedroom', 'the']\n",
      "12\t(2, 2)\t0.0\t['to', 'went', '**EOS**', 'Fred', '**EOS**', 'bedroom', 'the']\n",
      "13\t(2, 2)\t0.0\t['to', 'went', 'Fred', '**EOS**', '**EOS**', 'bedroom', 'the']\n",
      "14\t(2, 2)\t0.0\t['to', 'went', '**EOS**', 'Fred', '**EOS**', 'bedroom', 'the']\n",
      "15\t(2, 2)\t0.0\t['to', 'went', 'Fred', '**EOS**', '**EOS**', 'bedroom', 'the']\n",
      " Example 0: 0\n",
      " Example 50: 0\n",
      " Example 100: 0\n",
      " Example 150: 0\n",
      " Example 200: 0\n",
      " Example 250: 0\n",
      " Example 300: 0\n",
      " Example 350: 0\n",
      " Example 400: 0\n",
      " Example 450: 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):\n",
    "    cur_acc, cur_obj = accuracy(validate, seed=123123, repeats=3)\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        saver.save(session, \"babi_model.chpt\")\n",
    "    print(\"Accuracy before epoch %d => accuracy: %.1f %%, avg_objective: %.1f\" % (epoch, 100.0 * cur_acc, cur_obj))\n",
    "    run_example(random.choice(validate), training=False, debug=True)\n",
    "    random.shuffle(train)\n",
    "    no_successful = 0\n",
    "    for i, ex in enumerate(train):\n",
    "        r = run_example(ex)\n",
    "        if r.success(): no_successful += 1\n",
    "        if i % 50 == 0:\n",
    "            print(\" Example %d: %d\" % (i, no_successful), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\t(0, 2)\t0.0\t['discarded', '**EOS**', 'there', 'John', 'milk', 'the']\n",
      "2\t(0, 2)\t-2.0\t['there', '**EOS**', 'discarded', 'John', 'milk', 'the']\n",
      "3\t(0, 2)\t-2.0\t['discarded', '**EOS**', 'there', 'John', 'milk', 'the']\n",
      "4\t(0, 2)\t-2.0\t['there', '**EOS**', 'discarded', 'John', 'milk', 'the']\n",
      "5\t(0, 2)\t-2.0\t['discarded', '**EOS**', 'there', 'John', 'milk', 'the']\n",
      "6\t(0, 2)\t-2.0\t['there', '**EOS**', 'discarded', 'John', 'milk', 'the']\n",
      "7\t(0, 2)\t-2.0\t['discarded', '**EOS**', 'there', 'John', 'milk', 'the']\n",
      "8\t(0, 2)\t-2.0\t['there', '**EOS**', 'discarded', 'John', 'milk', 'the']\n",
      "9\t(0, 2)\t-2.0\t['discarded', '**EOS**', 'there', 'John', 'milk', 'the']\n",
      "10\t(0, 2)\t-2.0\t['there', '**EOS**', 'discarded', 'John', 'milk', 'the']\n",
      "11\t(0, 2)\t-2.0\t['discarded', '**EOS**', 'there', 'John', 'milk', 'the']\n",
      "12\t(0, 2)\t-2.0\t['there', '**EOS**', 'discarded', 'John', 'milk', 'the']\n",
      "13\t(0, 2)\t-2.0\t['discarded', '**EOS**', 'there', 'John', 'milk', 'the']\n",
      "14\t(0, 2)\t-2.0\t['there', '**EOS**', 'discarded', 'John', 'milk', 'the']\n",
      "15\t(0, 2)\t-2.0\t['discarded', '**EOS**', 'there', 'John', 'milk', 'the']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Reshuffling at 0x7fbe33b2fbe0>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(current_controller.experience))\n",
    "run_example(validate[4], training=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37333333333333335, 3.2666666666666666)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test, seed=4434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t(1, 4)\t['to', 'Daniel', '**EOS**', 'kitchen', 'the', 'travelled']\n",
      "1\t(1, 4)\t['to', 'the', '**EOS**', 'kitchen', 'Daniel', 'travelled']\n",
      "2\t(1, 4)\t['to', 'Daniel', '**EOS**', 'kitchen', 'the', 'travelled']\n",
      "3\t(1, 4)\t['to', 'the', '**EOS**', 'kitchen', 'Daniel', 'travelled']\n",
      "4\t(1, 4)\t['to', 'Daniel', '**EOS**', 'kitchen', 'the', 'travelled']\n",
      "5\t(1, 4)\t['to', 'the', '**EOS**', 'kitchen', 'Daniel', 'travelled']\n",
      "6\t(1, 4)\t['to', 'Daniel', '**EOS**', 'kitchen', 'the', 'travelled']\n",
      "7\t(1, 4)\t['to', 'the', '**EOS**', 'kitchen', 'Daniel', 'travelled']\n",
      "8\t(1, 4)\t['to', 'Daniel', '**EOS**', 'kitchen', 'the', 'travelled']\n",
      "9\t(1, 4)\t['to', 'the', '**EOS**', 'kitchen', 'Daniel', 'travelled']\n",
      "10\t(1, 4)\t['to', 'Daniel', '**EOS**', 'kitchen', 'the', 'travelled']\n",
      "11\t(1, 4)\t['to', 'the', '**EOS**', 'kitchen', 'Daniel', 'travelled']\n",
      "12\t(1, 4)\t['to', 'Daniel', '**EOS**', 'kitchen', 'the', 'travelled']\n",
      "13\t(1, 4)\t['to', 'the', '**EOS**', 'kitchen', 'Daniel', 'travelled']\n",
      "14\t(1, 4)\t['to', 'Daniel', '**EOS**', 'kitchen', 'the', 'travelled']\n"
     ]
    }
   ],
   "source": [
    "r = run_example(test[0], training=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
