{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dali.core as D\n",
    "from dali import activation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from dali.models import MLP\n",
    "from dali.utils import Solver, median_smoothing\n",
    "from IPython.display import clear_output, display, HTML\n",
    "from euclid import Circle, Point2, Vector2, LineSegment2\n",
    "\n",
    "import svg\n",
    "\n",
    "from event_queue import EventQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.config.default_device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class DeepQ(object):\n",
    "    def __init__(self, observation_size,\n",
    "                       num_actions,\n",
    "                       observation_to_actions,\n",
    "                       solver,\n",
    "                       random_action_probability=0.05,\n",
    "                       exploration_period=1000,\n",
    "                       minibatch_size=32,\n",
    "                       discount_rate=0.95,\n",
    "                       max_experience=30000):\n",
    "        \"\"\"Initialized the Deepq object.\n",
    "        \n",
    "        Based on:\n",
    "            https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "            \n",
    "        Parameters\n",
    "        -------\n",
    "        observation_size : int\n",
    "            length of the vector passed as observation\n",
    "        num_actions : int\n",
    "            number of actions that the model can execute\n",
    "        observation_to_actions: dali model\n",
    "            model that implements activate function\n",
    "            that can take in observation vector or a batch\n",
    "            and returns scores (of unbounded values) for each\n",
    "            action for each observation.\n",
    "            input shape:  [batch_size, observation_size]\n",
    "            output shape: [batch_size, num_actions]\n",
    "        solver: dali solver\n",
    "            solver over observation_to_actions,\n",
    "            must implement the step function\n",
    "        random_action_probability: float (0 to 1)\n",
    "        exploration_period: int\n",
    "            probability of choosing a random \n",
    "            action (epsilon form paper) annealed linearly\n",
    "            from 1 to random_action_probability over\n",
    "            exploration_period\n",
    "        minibatch_size: int\n",
    "            number of state,action,reward,newstate\n",
    "            tuples considered during experience reply\n",
    "        dicount_rate: float (0 to 1)\n",
    "            how much we care about future rewards.\n",
    "        max_experience: int\n",
    "            maximum size of the reply buffer\n",
    "        \"\"\"\n",
    "        # memorize arguments\n",
    "        self.observation_size          = observation_size\n",
    "        self.num_actions               = num_actions\n",
    "        \n",
    "        self.observation_to_actions    = observation_to_actions\n",
    "        self.solver                    = solver\n",
    "        \n",
    "        self.random_action_probability = random_action_probability\n",
    "        self.exploration_period        = exploration_period\n",
    "        self.minibatch_size            = minibatch_size\n",
    "        self.discount_rate             = discount_rate\n",
    "        self.max_experience            = max_experience\n",
    "        \n",
    "        # deepq state\n",
    "        self.actions_executed_so_far = 0\n",
    "        self.experience = deque()\n",
    "        \n",
    "        self.error_history = []\n",
    "        \n",
    "    def linear_annealing(self, n, total, p_initial, p_final):\n",
    "        \"\"\"Linear annealing between p_initial and p_final\n",
    "        over total steps - computes value at step n\"\"\"\n",
    "        if n >= total:\n",
    "            return p_final\n",
    "        else:\n",
    "            return p_initial - (n * (p_initial - p_final)) / (total)\n",
    "\n",
    "    def activate(self, observation):\n",
    "        \"\"\"Given observation or a batch returns action scores.\"\"\"\n",
    "        action_scores = self.observation_to_actions.activate(observation)\n",
    "        assert action_scores.shape[1] == self.num_actions, \\\n",
    "                \"number of columns in the output of `observation_to_actions` must be equal to number of actions.\"\n",
    "        assert action_scores.shape[0] == observation.shape[0], \\\n",
    "                \"number of output rows of `observation_to_actions` must be equal to number of input rows\"\n",
    "        return action_scores\n",
    "    \n",
    "    def action(self, observation):\n",
    "        \"\"\"Given observation returns the action that should be chosen using\n",
    "        DeepQ learning strategy. Does not backprop.\"\"\"\n",
    "        assert len(observation.shape) == 1, \\\n",
    "                \"Action is performed based on single observation.\"\n",
    "\n",
    "        self.actions_executed_so_far += 1\n",
    "        exploration_p = self.linear_annealing(self.actions_executed_so_far,\n",
    "                                              self.exploration_period,\n",
    "                                              1.0,\n",
    "                                              self.random_action_probability)\n",
    "                                                 \n",
    "        if random.random() < exploration_p:\n",
    "            return random.randint(0, self.num_actions - 1)\n",
    "        else:\n",
    "            with D.NoBackprop():\n",
    "                observation_dali = D.Mat(observation[np.newaxis,:], constant=True)\n",
    "                assert observation_dali.shape == (1, observation.shape[0])\n",
    "                action_scores = self.activate(observation_dali)\n",
    "                return D.MatOps.argmax(action_scores, axis=1)[0]\n",
    "        \n",
    "    def store(self, observation, action, reward, newobservation):\n",
    "        \"\"\"Store experience, where starting with observation and\n",
    "        execution action, we arrived at the newobservation and got the\n",
    "        reward reward\n",
    "        \n",
    "        If newstate is None, the state/action pair is assumed to be terminal\n",
    "        \"\"\"\n",
    "        self.experience.append((observation, action, reward, newobservation))\n",
    "        if len(self.experience) > self.max_experience:\n",
    "            self.experience.popleft()\n",
    "    \n",
    "    def training_step(self):\n",
    "        \"\"\"Pick a self.minibatch_size exeperiences from reply buffer\n",
    "        and backpropage the value function.\n",
    "        \"\"\"\n",
    "        if len(self.experience) <  self.minibatch_size:\n",
    "            return\n",
    "        \n",
    "        # sample experience. \n",
    "        samples   = random.sample(range(len(self.experience)), self.minibatch_size)\n",
    "        samples   = [self.experience[i] for i in samples]\n",
    "        \n",
    "        # bach states\n",
    "        states    = np.empty((len(samples), self.observation_size))\n",
    "        newstates = np.empty((len(samples), self.observation_size))\n",
    "        action_mask    = np.zeros((len(samples), self.num_actions))\n",
    "        \n",
    "        newstates_mask = np.empty((len(samples),))\n",
    "        rewards        = np.empty((len(samples),))\n",
    "        \n",
    "        for i, (state, action, reward, newstate) in enumerate(samples):\n",
    "            states[i] = state\n",
    "            action_mask[i] = 0\n",
    "            action_mask[i][action] = 1\n",
    "            rewards[i] = reward\n",
    "            if newstate is not None:\n",
    "                newstates[i] = state\n",
    "                newstates_mask[i] = 1\n",
    "            else:\n",
    "                newstates[i] = 0\n",
    "                newstates_mask[i] = 0\n",
    "                \n",
    "        # convert to dali, steal numpy memory, do not compute gradient (that's constant)\n",
    "        states      = D.Mat(states,      borrow=True, constant=True)\n",
    "        newstates   = D.Mat(newstates,   borrow=True, constant=True)\n",
    "        action_mask = D.Mat(action_mask, borrow=True, constant=True)\n",
    "        \n",
    "        # compute target value functions\n",
    "        with D.NoBackprop():\n",
    "            action_scores = self.activate(newstates)\n",
    "        # rowwise max - best achievable value function for each sample.\n",
    "        newstates_value = action_scores.w.max(axis=1) * newstates_mask\n",
    "        targets = rewards + self.discount_rate * newstates_value\n",
    "\n",
    "        # convert to dali, steal numpy memory, do not compute gradient (that's constant)\n",
    "        targets     = D.Mat(targets,     borrow=True, constant=True)\n",
    "        \n",
    "        # this computation will be backpropagated.\n",
    "        action_scores = self.activate(states)\n",
    "        relevant_actions = (action_scores * action_mask).sum(axis=1)\n",
    "        error = (relevant_actions - targets)**2\n",
    "        error.grad()\n",
    "        \n",
    "        # compute gradient\n",
    "        D.Graph.backward()\n",
    "        # apply gradient\n",
    "        solver.step()\n",
    "        \n",
    "        self.error_history.append(float(error.w.sum() / len(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class GameObject(object):\n",
    "    def __init__(self, position, speed, obj_type, settings):\n",
    "        \"\"\"Esentially represents circles of different kinds, which have\n",
    "        position and speed.\"\"\"\n",
    "        self.settings = settings\n",
    "        self.radius = self.settings[\"object_radius\"]\n",
    "        \n",
    "        self.obj_type = obj_type\n",
    "        self.position = position\n",
    "        self.speed    = speed\n",
    "                \n",
    "    def wall_collisions(self):\n",
    "        \"\"\"Update speed upon collision with the wall.\"\"\"\n",
    "        world_size = self.settings[\"world_size\"]\n",
    "\n",
    "        for dim in range(2):\n",
    "            if self.position[dim] - self.radius       <= 0               and self.speed[dim] < 0:\n",
    "                self.speed[dim] = - self.speed[dim]\n",
    "            elif self.position[dim] + self.radius + 1 >= world_size[dim] and self.speed[dim] > 0:\n",
    "                self.speed[dim] = - self.speed[dim]\n",
    "        \n",
    "    def move(self, dt):\n",
    "        \"\"\"Move as if dt seconds passed\"\"\"\n",
    "        self.position += dt * self.speed\n",
    "        self.position = Point2(*self.position)\n",
    "        \n",
    "    def step(self, dt):\n",
    "        \"\"\"Move and bounce of walls.\"\"\"\n",
    "        self.wall_collisions()\n",
    "        self.move(dt)\n",
    "        \n",
    "    def as_circle(self):\n",
    "        return Circle(self.position, float(self.radius))\n",
    "        \n",
    "    def draw(self):\n",
    "        \"\"\"Return svg object for this item.\"\"\"\n",
    "        color = self.settings[\"colors\"][self.obj_type]\n",
    "        return svg.Circle(self.position + Point2(10, 10), self.radius, color=color)\n",
    "\n",
    "class KarpathyGame(object):\n",
    "    def __init__(self, settings):\n",
    "        \"\"\"Initiallize game simulator with settings\"\"\"\n",
    "        self.settings = settings\n",
    "        self.size  = np.array(self.settings[\"world_size\"])\n",
    "        self.walls = [LineSegment2(Point2(0,0),                        Point2(0,self.size[1])),\n",
    "                      LineSegment2(Point2(0,self.size[1]),             Point2(self.size[0], self.size[1])),\n",
    "                      LineSegment2(Point2(self.size[0], self.size[1]), Point2(self.size[0], 0)),\n",
    "                      LineSegment2(Point2(self.size[0], 0),            Point2(0,0))]\n",
    "        \n",
    "        self.hero = GameObject(Point2(*self.settings[\"hero_initial_position\"]),\n",
    "                               Vector2(*self.settings[\"hero_initial_speed\"]),\n",
    "                               \"hero\",\n",
    "                               self.settings)\n",
    "        \n",
    "        self.objects = []\n",
    "        for obj_type, number in settings[\"num_objects\"].items():\n",
    "            for _ in range(number):\n",
    "                self.spawn_object(obj_type)\n",
    "        \n",
    "        self.observation_lines = self.generate_observation_lines()\n",
    "                \n",
    "        self.object_reward = 0\n",
    "        self.collected_rewards = []\n",
    "        \n",
    "        # every observation_line sees one of objects or wall and\n",
    "        # two numbers representing speed of the object (if applicable)\n",
    "        self.eye_observation_size = len(self.settings[\"objects\"]) + 3\n",
    "        # additionally there are two numbers representing agents own speed.\n",
    "        self.observation_size = self.eye_observation_size * len(self.observation_lines) + 2\n",
    "        \n",
    "        self.directions = [Vector2(*d) for d in [[1,0], [0,1], [-1,0],[0,-1]]]\n",
    "        self.num_actions      = len(self.directions)\n",
    "        \n",
    "        self.objects_eaten = defaultdict(lambda: 0)\n",
    "        \n",
    "    def perform_action(self, action_id):\n",
    "        \"\"\"Change speed to one of hero vectors\"\"\"\n",
    "        assert 0 <= action_id < self.num_actions\n",
    "        self.hero.speed *= 0.95\n",
    "        self.hero.speed += self.directions[action_id] * self.settings[\"delta_v\"]\n",
    "            \n",
    "    def spawn_object(self, obj_type):\n",
    "        \"\"\"Spawn object of a given type and add it to the objects array\"\"\"\n",
    "        radius = self.settings[\"object_radius\"]\n",
    "        position = np.random.uniform([radius, radius], self.size - radius)\n",
    "        position = Point2(*position)\n",
    "        max_speed = np.array(self.settings[\"maximum_speed\"])\n",
    "        speed    = np.random.uniform(-max_speed, max_speed).astype(float)\n",
    "        speed = Vector2(*speed)\n",
    "\n",
    "        self.objects.append(GameObject(position, speed, obj_type, self.settings))     \n",
    "                \n",
    "    def step(self, dt):\n",
    "        \"\"\"Simulate all the objects for a given ammount of time.\n",
    "        \n",
    "        Also resolve collisions with the hero\"\"\"\n",
    "        for obj in self.objects + [self.hero] :\n",
    "            obj.step(dt)\n",
    "        self.resolve_collisions()\n",
    "\n",
    "    def squared_distance(self, p1, p2):\n",
    "        return (p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2\n",
    "        \n",
    "    def resolve_collisions(self):\n",
    "        \"\"\"If hero touches, hero eats. Also reward gets updated.\"\"\"\n",
    "        collision_distance = 2 * self.settings[\"object_radius\"]\n",
    "        collision_distance2 = collision_distance ** 2\n",
    "        to_remove = []\n",
    "        for obj in self.objects:\n",
    "            if self.squared_distance(self.hero.position, obj.position) < collision_distance2:\n",
    "                to_remove.append(obj)\n",
    "        for obj in to_remove:\n",
    "            self.objects.remove(obj)\n",
    "            self.objects_eaten[obj.obj_type] += 1\n",
    "            self.object_reward += self.settings[\"object_reward\"][obj.obj_type]\n",
    "            self.spawn_object(obj.obj_type)\n",
    "        \n",
    "    def inside_walls(self, point):\n",
    "        \"\"\"Check if the point is inside the walls\"\"\"\n",
    "        EPS = 1e-4\n",
    "        return (EPS <= point[0] < self.size[0] - EPS and\n",
    "                EPS <= point[1] < self.size[1] - EPS)\n",
    "        \n",
    "    def observe(self):\n",
    "        \"\"\"Return observation vector. For all the observation directions it returns representation\n",
    "        of the closest object to the hero - might be nothing, another object or a wall.\n",
    "        Representation of observation for all the directions will be concatenated.\n",
    "        \"\"\"\n",
    "        num_obj_types = len(self.settings[\"objects\"]) + 1 # and wall\n",
    "        max_speed_x, max_speed_y = self.settings[\"maximum_speed\"]\n",
    "        \n",
    "        observable_distance = self.settings[\"observation_line_length\"]\n",
    "        relevant_objects = [obj for obj in self.objects \n",
    "                            if obj.position.distance(self.hero.position) < observable_distance]\n",
    "        # objects sorted from closest to furthest\n",
    "        relevant_objects.sort(key=lambda x: x.position.distance(self.hero.position))\n",
    "        \n",
    "        observation        = np.zeros(self.observation_size)\n",
    "        observation_offset = 0 \n",
    "        for i, observation_line in enumerate(self.observation_lines):\n",
    "            # shift to hero position\n",
    "            observation_line = LineSegment2(self.hero.position + Vector2(*observation_line.p1),\n",
    "                                            self.hero.position + Vector2(*observation_line.p2))\n",
    "\n",
    "            observed_object = None\n",
    "            # if end of observation line is outside of walls, we see the wall.\n",
    "            if not self.inside_walls(observation_line.p2):\n",
    "                observed_object = \"**wall**\"\n",
    "            for obj in relevant_objects:\n",
    "                if observation_line.distance(obj.position) < self.settings[\"object_radius\"]:\n",
    "                    observed_object = obj\n",
    "                    break\n",
    "            object_type_id = None\n",
    "            speed_x, speed_y = 0, 0\n",
    "            proximity = 0\n",
    "            if observed_object == \"**wall**\": # wall seen \n",
    "                object_type_id = num_obj_types - 1\n",
    "                # a wall has fairly low speed...\n",
    "                speed_x, speed_y = 0, 0\n",
    "                # best candidate is intersection between\n",
    "                # observation_line and a wall, that's\n",
    "                # closest to the hero\n",
    "                best_candidate = None\n",
    "                for wall in self.walls:\n",
    "                    candidate = observation_line.intersect(wall)\n",
    "                    if candidate is not None:\n",
    "                        if (best_candidate is None or \n",
    "                                best_candidate.distance(self.hero.position) >\n",
    "                                candidate.distance(self.hero.position)):\n",
    "                            best_candidate = candidate\n",
    "                if best_candidate is None:\n",
    "                    # assume it is due to rounding errors\n",
    "                    # and wall is barely touching observation line\n",
    "                    proximity = observable_distance\n",
    "                else:\n",
    "                    proximity = best_candidate.distance(self.hero.position)\n",
    "            elif observed_object is not None: # agent seen\n",
    "                object_type_id = self.settings[\"objects\"].index(observed_object.obj_type)\n",
    "                speed_x, speed_y = tuple(observed_object.speed)\n",
    "                intersection_segment = obj.as_circle().intersect(observation_line)\n",
    "                assert intersection_segment is not None\n",
    "                proximity = min(intersection_segment.p1.distance(self.hero.position),\n",
    "                                intersection_segment.p2.distance(self.hero.position))\n",
    "            for object_type_idx_loop in range(num_obj_types):\n",
    "                observation[observation_offset + object_type_idx_loop] = 1.0\n",
    "            if object_type_id is not None:\n",
    "                observation[observation_offset + object_type_id] = proximity / observable_distance\n",
    "            observation[observation_offset + num_obj_types] =     speed_x   / max_speed_x\n",
    "            observation[observation_offset + num_obj_types + 1] = speed_y   / max_speed_y\n",
    "            assert num_obj_types + 2 == self.eye_observation_size\n",
    "            observation_offset += self.eye_observation_size\n",
    "        \n",
    "        observation[observation_offset]     = self.hero.speed[0] / max_speed_x\n",
    "        observation[observation_offset + 1] = self.hero.speed[1] / max_speed_y\n",
    "        assert observation_offset + 2 == self.observation_size\n",
    "        \n",
    "        return observation        \n",
    "    \n",
    "    def distance_to_walls(self):\n",
    "        \"\"\"Returns distance of a hero to walls\"\"\"\n",
    "        res = float('inf')\n",
    "        for wall in self.walls:\n",
    "            res = min(res, self.hero.position.distance(wall))\n",
    "        return res - self.settings[\"object_radius\"]\n",
    "        \n",
    "    def collect_reward(self):\n",
    "        \"\"\"Return accumulated object eating score + current distance to walls score\"\"\"\n",
    "        wall_reward =  self.settings[\"wall_distance_penalty\"] * \\\n",
    "                       np.exp(-self.distance_to_walls() / self.settings[\"tolerable_distance_to_wall\"])\n",
    "        assert wall_reward < 1e-3, \"You are rewarding hero for being close to the wall!\"\n",
    "        total_reward = wall_reward + self.object_reward\n",
    "        self.object_reward = 0\n",
    "        self.collected_rewards.append(total_reward)\n",
    "        return total_reward\n",
    "        \n",
    "    def plot_reward(self, smoothing = 30):\n",
    "        \"\"\"Plot evolution of reward over time.\"\"\"\n",
    "        plottable = self.collected_rewards[:]\n",
    "        while len(plottable) > 1000:\n",
    "            for i in range(0, len(plottable) - 1, 2):\n",
    "                plottable[i//2] = (plottable[i] + plottable[i+1]) / 2\n",
    "            plottable = plottable[:(len(plottable) // 2)]\n",
    "        x = []\n",
    "        for  i in range(smoothing, len(plottable)):\n",
    "            chunk = plottable[i-smoothing:i]\n",
    "            x.append(sum(chunk) / len(chunk))\n",
    "        plt.plot(list(range(len(x))), x)\n",
    "        \n",
    "    def generate_observation_lines(self):\n",
    "        \"\"\"Generate observation segments in settings[\"num_observation_lines\"] directions\"\"\"\n",
    "        result = []\n",
    "        start = Point2(0.0, 0.0)\n",
    "        end   = Point2(self.settings[\"observation_line_length\"],\n",
    "                       self.settings[\"observation_line_length\"])\n",
    "        for angle in np.linspace(0, 2*np.pi, self.settings[\"num_observation_lines\"], endpoint=False):\n",
    "            rotation = Point2(np.cos(angle), np.sin(angle))\n",
    "            current_start = Point2(start[0] * rotation[0], start[1] * rotation[1])\n",
    "            current_end   = Point2(end[0]   * rotation[0], end[1]   * rotation[1])\n",
    "            result.append( LineSegment2(current_start, current_end))\n",
    "        return result\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return self.to_html()\n",
    "    \n",
    "    def to_html(self, stats=[]):\n",
    "        \"\"\"Return svg representation of the simulator\"\"\"\n",
    "        scene = svg.Scene((self.size[0] + 20, self.size[1] + 20 + 20 * len(stats)))\n",
    "        scene.add(svg.Rectangle((10, 10), self.size))\n",
    "\n",
    "            \n",
    "        for line in self.observation_lines:\n",
    "            scene.add(svg.Line(line.p1 + self.hero.position + Point2(10,10),\n",
    "                               line.p2 + self.hero.position + Point2(10,10)))\n",
    "        \n",
    "        for obj in self.objects + [self.hero] :\n",
    "            scene.add(obj.draw())\n",
    "        \n",
    "        offset = self.size[1] + 15\n",
    "        for txt in stats:              \n",
    "            scene.add(svg.Text((10, offset + 20), txt, 15))\n",
    "            offset += 20\n",
    "                          \n",
    "        return scene\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_settings = {\n",
    "    'objects': [\n",
    "        'friend',\n",
    "        'enemy',\n",
    "#         'boss'\n",
    "    ],\n",
    "    'colors': {\n",
    "        'hero':   'yellow',\n",
    "        'friend': 'green',\n",
    "        'enemy':  'red',\n",
    "#         'boss':   'orange',\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'friend': 1,\n",
    "        'enemy': -1,\n",
    "#         'boss':  -20,\n",
    "    },\n",
    "    'world_size': (700,500),\n",
    "    'hero_initial_position': [400, 300],\n",
    "    'hero_initial_speed':    [0,   0],\n",
    "    \"maximum_speed\":         [50, 50],\n",
    "    \"object_radius\": 10.0,\n",
    "    \"num_objects\": {\n",
    "        \"friend\" : 25,\n",
    "        \"enemy\" :  25,\n",
    "#         \"boss\" :   5,\n",
    "    },\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 120.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -0.0,\n",
    "    \"delta_v\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# brain maps from observation to action q values. Here it is a simple mlp\n",
    "brain = MLP([g.observation_size,], [100, 100, g.num_actions], \n",
    "            [activation.tanh, activation.tanh, activation.identity])\n",
    "# solver over brian - here simple sgd\n",
    "solver = Solver(brain.parameters(), \"rmsprop\", learning_rate= 0.005)\n",
    "# solver = Solver(brain.parameters(), \"sgd\", learning_rate= 0.001)\n",
    "\n",
    "# DeepQ object\n",
    "current_controller = DeepQ(g.observation_size, g.num_actions, brain, solver,\n",
    "                           discount_rate=0.9, exploration_period=5000, max_experience=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "CONTROLLER_PATH = \"controller.pkz\"\n",
    "SETTINGS_PATH   = \"settings.json\"\n",
    "\n",
    "def save():\n",
    "    with open(SETTINGS_PATH, \"w\") as f:\n",
    "        json.dump(current_settings, f)\n",
    "    with open(CONTROLLER_PATH, \"wb\") as f:\n",
    "        pickle.dump(current_controller, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulate(game,\n",
    "             controller,\n",
    "             fps=60,\n",
    "             actions_per_game_second=60,\n",
    "             simulation_resultion=0.001,\n",
    "             speed=1.0,\n",
    "             store_every_nth=5,\n",
    "             train_every_nth=5):\n",
    "    \"\"\"Start the simulation. Performs three tasks\n",
    "       \n",
    "        - visualizes simulation in iPython notebook\n",
    "        - advances game simulator state\n",
    "        - reports state to controller and chooses actions\n",
    "          to be performed.\n",
    "    \"\"\"\n",
    "    eq = EventQueue()\n",
    "    \n",
    "    time_between_frames  = 1.0 / fps\n",
    "    game_time_between_actions = 1.0 / actions_per_game_second\n",
    "    \n",
    "    simulation_resultion /= speed\n",
    "    \n",
    "    ###### VISUALIZATION\n",
    "    def visualize():\n",
    "        clear_output(wait=True)\n",
    "        recent_reward = game.collected_rewards[-100:] + [0]\n",
    "        objects_eaten_str = ', '.join([\"%s: %s\" % (o,c) for o,c in game.objects_eaten.items()])\n",
    "        display(game.to_html([\n",
    "            \"DTW        = %.1f\" % (game.distance_to_walls(),),\n",
    "            \"experience = %d\" % (len(controller.experience),),\n",
    "            \"reward = %.1f\" % (sum(recent_reward)/len(recent_reward),),\n",
    "            \"objects eaten => %s\" % (objects_eaten_str,),\n",
    "\n",
    "        ]))\n",
    "    eq.schedule_recurring(visualize, time_between_frames)\n",
    "\n",
    "    \n",
    "    ###### CONTROL\n",
    "    \n",
    "    last_observation = None\n",
    "    last_action      = None\n",
    "    actions_so_far = 0\n",
    "    \n",
    "    def control():\n",
    "        nonlocal last_observation\n",
    "        nonlocal last_action\n",
    "        nonlocal actions_so_far\n",
    "        # sense\n",
    "        new_observation = game.observe()\n",
    "        reward          = game.collect_reward()\n",
    "        # store last transition\n",
    "        actions_so_far += 1\n",
    "        if last_observation is not None and actions_so_far % store_every_nth == 0:\n",
    "            controller.store(last_observation, last_action, reward, new_observation)\n",
    "        # act\n",
    "        new_action = controller.action(new_observation)\n",
    "        game.perform_action(new_action)\n",
    "        last_action = new_action\n",
    "        last_observation = new_observation\n",
    "        \n",
    "        #train\n",
    "        if last_observation is not None and actions_so_far % train_every_nth == 0:\n",
    "            controller.training_step()\n",
    "    \n",
    "    ##### SIMULATION\n",
    "    \n",
    "    simulated_up_to = time.time()\n",
    "    game_time_since_last_action = 0\n",
    "\n",
    "    def simulate_game():\n",
    "        nonlocal simulated_up_to\n",
    "        nonlocal game_time_since_last_action\n",
    "        while simulated_up_to < time.time():\n",
    "            game.step(simulation_resultion)\n",
    "            simulated_up_to += simulation_resultion / speed\n",
    "            game_time_since_last_action += simulation_resultion\n",
    "            if game_time_since_last_action > game_time_between_actions:\n",
    "                control()\n",
    "                game_time_since_last_action = 0\n",
    "        \n",
    "    eq.schedule_recurring(simulate_game, time_between_frames)\n",
    "    \n",
    "    eq.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# g.__class__ = KarpathyGame\n",
    "# np.set_printoptions(formatter={'float': (lambda x: '%.2f' % (x,))})\n",
    "# x = g.observe()\n",
    "# new_shape = (x[:-2].shape[0]//g.eye_observation_size, g.eye_observation_size)\n",
    "# print(x[:-2].reshape(new_shape))\n",
    "# print(x[-2:])\n",
    "# g.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\"?>\n",
       "\n",
       "<svg height=\"600\" width=\"720\" >\n",
       "\n",
       " <g style=\"fill-opacity:1.0; stroke:black;\n",
       "\n",
       "  stroke-width:1;\">\n",
       "\n",
       "  <rect x=\"10\" y=\"10\" height=\"500\"\n",
       "\n",
       "        width=\"700\" style=fill:none; />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"257\" y2=\"215\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"254\" y2=\"238\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"248\" y2=\"261\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"237\" y2=\"282\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"222\" y2=\"300\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"203\" y2=\"315\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"183\" y2=\"326\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"160\" y2=\"333\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"137\" y2=\"335\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"113\" y2=\"333\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"91\" y2=\"326\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"70\" y2=\"315\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"52\" y2=\"300\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"37\" y2=\"282\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"26\" y2=\"261\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"19\" y2=\"238\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"17\" y2=\"215\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"19\" y2=\"192\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"26\" y2=\"169\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"37\" y2=\"148\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"52\" y2=\"130\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"70\" y2=\"115\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"91\" y2=\"104\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"113\" y2=\"97\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"137\" y2=\"95\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"160\" y2=\"97\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"183\" y2=\"104\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"203\" y2=\"115\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"222\" y2=\"130\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"237\" y2=\"148\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"248\" y2=\"169\" />\n",
       "\n",
       "  <line x1=\"137\" y1=\"215\" x2=\"254\" y2=\"192\" />\n",
       "\n",
       "  <circle cx=\"20\" cy=\"57\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"234\" cy=\"110\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"429\" cy=\"438\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"627\" cy=\"272\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"261\" cy=\"389\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"597\" cy=\"282\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"624\" cy=\"50\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"400\" cy=\"54\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"678\" cy=\"25\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"407\" cy=\"268\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"539\" cy=\"423\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"315\" cy=\"463\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"37\" cy=\"268\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"152\" cy=\"426\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"680\" cy=\"58\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"386\" cy=\"187\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"387\" cy=\"459\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"449\" cy=\"205\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"374\" cy=\"171\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"663\" cy=\"497\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"481\" cy=\"256\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"190\" cy=\"483\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"168\" cy=\"249\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"633\" cy=\"228\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"369\" cy=\"451\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"347\" cy=\"286\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"36\" cy=\"22\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"434\" cy=\"320\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"238\" cy=\"368\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"416\" cy=\"342\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"453\" cy=\"482\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"554\" cy=\"432\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"403\" cy=\"207\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"278\" cy=\"32\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"26\" cy=\"380\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"585\" cy=\"189\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"431\" cy=\"300\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"83\" cy=\"28\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"98\" cy=\"157\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"542\" cy=\"386\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"345\" cy=\"132\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"100\" cy=\"432\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"599\" cy=\"322\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"109\" cy=\"435\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"624\" cy=\"426\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"76\" cy=\"144\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"445\" cy=\"89\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"243\" cy=\"183\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"84\" cy=\"424\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"450\" cy=\"371\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"137\" cy=\"215\" r=\"10\"\n",
       "\n",
       "          style=fill:yellow; />\n",
       "\n",
       "  <text x=\"10\" y=\"535\" font-size=\"15\">\n",
       "\n",
       "   DTW        = 117.3\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"555\" font-size=\"15\">\n",
       "\n",
       "   experience = 98\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"575\" font-size=\"15\">\n",
       "\n",
       "   reward = 0.0\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"595\" font-size=\"15\">\n",
       "\n",
       "   objects eaten => enemy: 7, friend: 5\n",
       "\n",
       "  </text>\n",
       "\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<svg.Scene at 0x7fc158d1bf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.__class__ = KarpathyGame\n",
    "FPS, SPEED, RES = 1, 4.5, 0.1\n",
    "# FPS, SPEED, RES = 30, 1., 0.03\n",
    "\n",
    "simulate(g, current_controller, fps = FPS,\n",
    "         simulation_resultion=RES,\n",
    "         actions_per_game_second=10,\n",
    "         speed=SPEED,\n",
    "         store_every_nth=4,\n",
    "         train_every_nth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEACAYAAAB27puMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURQF/j/EHK31APwp8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc15a78ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.plot_reward(smoothing=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc15b5d39b0>]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEACAYAAABCl1qQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc15b2b0240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = median_smoothing(current_controller.error_history[::1], 1000)\n",
    "x = range(len(y))\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
