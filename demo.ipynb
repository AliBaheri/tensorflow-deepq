{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dali.core as D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from dali.models import MLP\n",
    "from dali.utils import Solver\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "import svg\n",
    "\n",
    "from event_queue import EventQueue\n",
    "from geometry import point_distance, point_projected_on_line, point_segment_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.config.default_device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class DeepQ(object):\n",
    "    def __init__(self, observation_size,\n",
    "                       num_actions,\n",
    "                       observation_to_actions,\n",
    "                       solver,\n",
    "                       random_action_probability=0.05,\n",
    "                       exploration_period=1000,\n",
    "                       minibatch_size=30,\n",
    "                       discount_rate=0.95,\n",
    "                       max_experience=20000):\n",
    "        \"\"\"Initialized the Deepq object.\n",
    "        \n",
    "        Based on:\n",
    "            https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "            \n",
    "        Parameters\n",
    "        -------\n",
    "        observation_size : int\n",
    "            length of the vector passed as observation\n",
    "        num_actions : int\n",
    "            number of actions that the model can execute\n",
    "        observation_to_actions: dali model\n",
    "            model that implements activate function\n",
    "            that can take in observation vector or a batch\n",
    "            and returns scores (of unbounded values) for each\n",
    "            action for each observation.\n",
    "            input shape:  [batch_size, observation_size]\n",
    "            output shape: [batch_size, num_actions]\n",
    "        solver: dali solver\n",
    "            solver over observation_to_actions,\n",
    "            must implement the step function\n",
    "        random_action_probability: float (0 to 1)\n",
    "        exploration_period: int\n",
    "            probability of choosing a random \n",
    "            action (epsilon form paper) annealed linearly\n",
    "            from 1 to random_action_probability over\n",
    "            exploration_period\n",
    "        minibatch_size: int\n",
    "            number of state,action,reward,newstate\n",
    "            tuples considered during experience reply\n",
    "        dicount_rate: float (0 to 1)\n",
    "            how much we care about future rewards.\n",
    "        max_experience: int\n",
    "            maximum size of the reply buffer\n",
    "        \"\"\"\n",
    "        # memorize arguments\n",
    "        self.observation_size          = observation_size\n",
    "        self.num_actions               = num_actions\n",
    "        \n",
    "        self.observation_to_actions    = observation_to_actions\n",
    "        self.solver                    = solver\n",
    "        \n",
    "        self.random_action_probability = random_action_probability\n",
    "        self.exploration_period        = exploration_period\n",
    "        self.minibatch_size            = minibatch_size\n",
    "        self.discount_rate             = discount_rate\n",
    "        self.max_experience            = max_experience\n",
    "        \n",
    "        # deepq state\n",
    "        self.actions_executed_so_far = 0\n",
    "        self.experience = deque()\n",
    "        \n",
    "    def linear_annealing(self, n, total, p_initial, p_final):\n",
    "        \"\"\"Linear annealing between p_initial and p_final\n",
    "        over total steps - computes value at step n\"\"\"\n",
    "        if n >= total:\n",
    "            return p_final\n",
    "        else:\n",
    "            return p_initial - (n * (p_initial - p_final)) / (total)\n",
    "\n",
    "    def activate(self, observation):\n",
    "        \"\"\"Given observation or a batch returns action scores.\"\"\"\n",
    "        action_scores = self.observation_to_actions.activate(observation)\n",
    "        assert action_scores.shape[1] == self.num_actions, \\\n",
    "                \"number of columns in the output of `observation_to_actions` must be equal to number of actions.\"\n",
    "        assert action_scores.shape[0] == observation.shape[0], \\\n",
    "                \"number of output rows of `observation_to_actions` must be equal to number of input rows\"\n",
    "        return action_scores\n",
    "    \n",
    "    def action(self, observation):\n",
    "        \"\"\"Given observation returns the action that should be chosen using\n",
    "        DeepQ learning strategy. Does not backprop.\"\"\"\n",
    "        assert len(observation.shape) == 1, \\\n",
    "                \"Action is performed based on single observation.\"\n",
    "\n",
    "        self.actions_executed_so_far += 1\n",
    "        exploration_p = self.linear_annealing(self.actions_executed_so_far,\n",
    "                                              self.exploration_period,\n",
    "                                              1.0,\n",
    "                                              self.random_action_probability)\n",
    "                                                 \n",
    "        if random.random() < exploration_p:\n",
    "            return random.randint(0, self.num_actions - 1)\n",
    "        else:\n",
    "            with D.NoBackprop():\n",
    "                observation_dali = D.Mat(observation[np.newaxis,:], constant=True)\n",
    "                assert observation_dali.shape == (1, observation.shape[0])\n",
    "                action_scores = self.activate(observation_dali)\n",
    "                return D.MatOps.argmax(action_scores, axis=1)[0]\n",
    "        \n",
    "    def store(self, observation, action, reward, newobservation):\n",
    "        \"\"\"Store experience, where starting with observation and\n",
    "        execution action, we arrived at the newobservation and got the\n",
    "        reward reward\n",
    "        \n",
    "        If newstate is None, the state/action pair is assumed to be terminal\n",
    "        \"\"\"\n",
    "        self.experience.append((observation, action, reward, newobservation))\n",
    "        if len(self.experience) > self.max_experience:\n",
    "            self.experience.popleft()\n",
    "    \n",
    "    def training_step(self):\n",
    "        \"\"\"Pick a self.minibatch_size exeperiences from reply buffer\n",
    "        and backpropage the value function.\n",
    "        \"\"\"\n",
    "        if len(self.experience) <  self.minibatch_size:\n",
    "            return\n",
    "        \n",
    "        # sample experience. \n",
    "        samples   = random.sample(range(len(self.experience)), self.minibatch_size)\n",
    "        samples   = [self.experience[i] for i in samples]\n",
    "        \n",
    "        # bach states\n",
    "        states    = np.empty((len(samples), self.observation_size))\n",
    "        newstates = np.empty((len(samples), self.observation_size))\n",
    "        action_mask    = np.zeros((len(samples), self.num_actions))\n",
    "        \n",
    "        newstates_mask = np.empty((len(samples),))\n",
    "        rewards        = np.empty((len(samples),))\n",
    "        \n",
    "        for i, (state, action, reward, newstate) in enumerate(samples):\n",
    "            states[i] = state\n",
    "            action_mask[i] = 0\n",
    "            action_mask[i][action] = 1\n",
    "            rewards[i] = reward\n",
    "            if newstate is not None:\n",
    "                newstates[i] = state\n",
    "                newstates_mask[i] = 1\n",
    "            else:\n",
    "                newstates[i] = 0\n",
    "                newstates_mask[i] = 0\n",
    "                \n",
    "        # convert to dali, steal numpy memory, do not compute gradient (that's constant)\n",
    "        states      = D.Mat(states,      borrow=True, constant=True)\n",
    "        newstates   = D.Mat(newstates,   borrow=True, constant=True)\n",
    "        action_mask = D.Mat(action_mask, borrow=True, constant=True)\n",
    "        \n",
    "        # compute target value functions\n",
    "        with D.NoBackprop():\n",
    "            action_scores = self.activate(newstates)\n",
    "        # rowwise max - best achievable value function for each sample.\n",
    "        newstates_value = action_scores.w.max(axis=1) * newstates_mask\n",
    "        targets = rewards + self.discount_rate * newstates_value\n",
    "\n",
    "        # convert to dali, steal numpy memory, do not compute gradient (that's constant)\n",
    "        targets     = D.Mat(targets,     borrow=True, constant=True)\n",
    "        \n",
    "        # this computation will be backpropagated.\n",
    "        action_scores = self.activate(states)\n",
    "        relevant_actions = (action_scores * action_mask).sum(axis=1)\n",
    "        error = (relevant_actions - targets)**2\n",
    "        error.grad()\n",
    "        \n",
    "        # compute gradient\n",
    "        D.Graph.backward()\n",
    "        # apply gradient\n",
    "        solver.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class GameObject(object):\n",
    "    def __init__(self, position, speed, obj_type, settings):\n",
    "        \"\"\"Esentially represents circles of different kinds, which have\n",
    "        position and speed.\"\"\"\n",
    "        self.settings = settings\n",
    "        self.radius = self.settings[\"object_radius\"]\n",
    "        \n",
    "        self.obj_type = obj_type\n",
    "        self.position = np.array(position, dtype=float)\n",
    "        self.speed = np.array(speed, dtype=float)\n",
    "        \n",
    "    def wall_collisions(self):\n",
    "        \"\"\"Update speed upon collision with the wall.\"\"\"\n",
    "        world_size = self.settings[\"world_size\"]\n",
    "        for dim in range(2):\n",
    "            if self.position[dim] - self.radius       <= 0               and self.speed[dim] < 0:\n",
    "                self.speed[dim] = - self.speed[dim]\n",
    "            elif self.position[dim] + self.radius + 1 >= world_size[dim] and self.speed[dim] > 0:\n",
    "                self.speed[dim] = - self.speed[dim]\n",
    "        \n",
    "    def move(self, dt):\n",
    "        \"\"\"Move as if dt seconds passed\"\"\"\n",
    "        self.position += dt * self.speed\n",
    "        \n",
    "    def step(self, dt):\n",
    "        \"\"\"Move and bounce of walls.\"\"\"\n",
    "        self.wall_collisions()\n",
    "        self.move(dt)\n",
    "        \n",
    "    def draw(self):\n",
    "        \"\"\"Return svg object for this item.\"\"\"\n",
    "        color = self.settings[\"colors\"][self.obj_type]\n",
    "        return svg.Circle(self.position.astype(int) + 10, self.radius, color=color)\n",
    "\n",
    "class KarpathyGame(object):\n",
    "    def __init__(self, settings):\n",
    "        \"\"\"Initiallize game simulator with settings\"\"\"\n",
    "        self.settings = settings\n",
    "        self.size = np.array(self.settings[\"world_size\"])\n",
    "        \n",
    "        self.hero = GameObject(self.settings[\"hero_initial_position\"].copy(),\n",
    "                               self.settings[\"hero_initial_speed\"].copy(),\n",
    "                               \"hero\",\n",
    "                               self.settings)\n",
    "        \n",
    "        self.objects = []\n",
    "        for obj_type, number in settings[\"num_objects\"].items():\n",
    "            for _ in range(number):\n",
    "                self.spawn_object(obj_type)\n",
    "        \n",
    "        self.observation_lines = self.generate_observation_lines()\n",
    "        \n",
    "        self.action_vectors = [np.array(a) for a in self.settings[\"actions\"]]\n",
    "        \n",
    "        self.object_reward = 0\n",
    "        self.collected_rewards = []\n",
    "        \n",
    "        self.observation_size = self.settings[\"observation_repr_size\"] * len(self.observation_lines)\n",
    "        self.num_actions      = len(self.action_vectors)\n",
    "        \n",
    "        self.objects_eaten = defaultdict(lambda: 0)\n",
    "        \n",
    "\n",
    "        \n",
    "    def perform_action(self, action_id):\n",
    "        \"\"\"Change speed to one of the allowed vectors\"\"\"\n",
    "        assert 0 <= action_id < self.num_actions\n",
    "        self.hero.speed = self.action_vectors[action_id]\n",
    "            \n",
    "    def spawn_object(self, obj_type):\n",
    "        \"\"\"Spawn object of a given type and add it to the objects array\"\"\"\n",
    "        radius = self.settings[\"object_radius\"]\n",
    "        position = np.random.uniform([radius, radius], self.size - radius).astype(float)\n",
    "        speed    = np.random.uniform([-100,-100], [100,100]).astype(float)\n",
    "        self.objects.append(GameObject(position, speed, obj_type, self.settings))     \n",
    "                \n",
    "    def step(self, dt):\n",
    "        \"\"\"Simulate all the objects for a given ammount of time.\n",
    "        \n",
    "        Also resolve collisions with the hero\"\"\"\n",
    "        for obj in self.objects + [self.hero] :\n",
    "            obj.step(dt)\n",
    "        self.resolve_collisions()\n",
    "\n",
    "    def resolve_collisions(self):\n",
    "        \"\"\"If hero touches, hero eats. Also reward gets updated.\"\"\"\n",
    "        to_remove = []\n",
    "        for obj in self.objects:\n",
    "            if np.linalg.norm(obj.position - self.hero.position) < 2 * self.settings[\"object_radius\"]:\n",
    "                to_remove.append(obj)\n",
    "        for obj in to_remove:\n",
    "            self.objects.remove(obj)\n",
    "            self.objects_eaten[obj.obj_type] += 1\n",
    "            self.object_reward += self.settings[\"object_reward\"][obj.obj_type]\n",
    "            self.spawn_object(obj.obj_type)\n",
    "        \n",
    "    def inside_walls(self, point):\n",
    "        \"\"\"Check if the point is inside the walls\"\"\"\n",
    "        return np.all(np.array([0,0]) <= point) and np.all(point < self.size)\n",
    "        \n",
    "    def observe(self):\n",
    "        \"\"\"Return observation vector. For all the observation directions it returns representation\n",
    "        of the closest object to the hero - might be nothing, another object or a wall.\n",
    "        Representation of observation for all the directions will be concatenated.\n",
    "        \"\"\"\n",
    "        observable_distance = self.settings[\"object_radius\"] + self.settings[\"observation_line_length\"]\n",
    "        relevant_objects = [obj for obj in self.objects \n",
    "                            if point_distance(obj.position, self.hero.position) < observable_distance]\n",
    "        # objects sorted from closest to furthest\n",
    "        relevant_objects.sort(key=lambda x: point_distance(x.position, self.hero.position))\n",
    "        observ_atom_sz = self.settings[\"observation_repr_size\"]\n",
    "        observation = np.zeros((observ_atom_sz * len(self.observation_lines),))\n",
    "        for i, (line_start, line_end) in enumerate(self.observation_lines):\n",
    "            line_start = line_start + self.hero.position\n",
    "            line_end   = line_end   + self.hero.position\n",
    "            observed_repr = self.settings[\"observation_repr\"][\"nothing\"]\n",
    "            if not self.inside_walls(line_end):\n",
    "                observed_repr = self.settings[\"observation_repr\"][\"wall\"]\n",
    "            for obj in relevant_objects:\n",
    "                if point_segment_distance(line_start, line_end, obj.position) < SETTINGS[\"object_radius\"]:\n",
    "                    observed_repr = self.settings[\"observation_repr\"][obj.obj_type]\n",
    "                    break\n",
    "            observation[i*observ_atom_sz:(i+1)*observ_atom_sz] = observed_repr\n",
    "        return observation        \n",
    "    \n",
    "    def distance_to_walls(self):\n",
    "        \"\"\"Returns distance of a hero to walls\"\"\"\n",
    "        tl = np.min(self.hero.position - self.settings[\"object_radius\"])\n",
    "        br = np.min(self.size - self.hero.position - self.settings[\"object_radius\"])\n",
    "        return np.min([tl,br])\n",
    "        \n",
    "    def collect_reward(self):\n",
    "        \"\"\"Return accumulated object eating score + current distance to walls score\"\"\"\n",
    "        wall_reward =  self.settings[\"wall_distance_penalty\"] * \\\n",
    "                       np.exp(-self.distance_to_walls() / self.settings[\"tolerable_distance_to_wall\"])\n",
    "        total_reward = wall_reward + self.object_reward\n",
    "        self.object_reward = 0\n",
    "        self.collected_rewards.append(total_reward)\n",
    "        return total_reward\n",
    "        \n",
    "    def plot_reward(self, smoothing = 30):\n",
    "        \"\"\"Plot evolution of reward over time.\"\"\"\n",
    "        plottable = self.collected_rewards[:]\n",
    "        while len(plottable) > 1000:\n",
    "            for i in range(0, len(plottable) - 1, 2):\n",
    "                plottable[i//2] = (plottable[i] + plottable[i+1]) / 2\n",
    "            plottable = plottable[:(len(plottable) // 2)]\n",
    "        x = []\n",
    "        for  i in range(smoothing, len(plottable)):\n",
    "            chunk = plottable[i-smoothing:i]\n",
    "            x.append(sum(chunk) / len(chunk))\n",
    "        plt.plot(list(range(len(x))), x)\n",
    "        \n",
    "    def generate_observation_lines(self):\n",
    "        \"\"\"Generate observation segments in settings[\"num_observation_lines\"] directions\"\"\"\n",
    "        result = []\n",
    "        start = np.array([self.settings[\"object_radius\"]* 1.1, self.settings[\"object_radius\"]* 1.1])\n",
    "        end   = np.array([self.settings[\"object_radius\"] + self.settings[\"observation_line_length\"],\n",
    "                          self.settings[\"object_radius\"] + self.settings[\"observation_line_length\"]])\n",
    "        for angle in np.linspace(0, 2*np.pi, self.settings[\"num_observation_lines\"], endpoint=False):\n",
    "            rotation = np.array([np.cos(angle), np.sin(angle)])\n",
    "            result.append((start * rotation, end * rotation))\n",
    "        return result\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return self.to_html()\n",
    "    \n",
    "    def to_html(self, stats):\n",
    "        \"\"\"Return svg representation of the simulator\"\"\"\n",
    "        scene = svg.Scene((self.size[0] + 20, self.size[1] + 20 + 20 * len(stats)))\n",
    "        scene.add(svg.Rectangle((10, 10), self.size))\n",
    "        for obj in self.objects + [self.hero] :\n",
    "            scene.add(obj.draw())\n",
    "            \n",
    "        for line_start, line_end in self.observation_lines:\n",
    "            scene.add(svg.Line(line_start + self.hero.position + 10, line_end + self.hero.position + 10))\n",
    "        \n",
    "        offset = self.size[1] + 15\n",
    "        for txt in stats:              \n",
    "            scene.add(svg.Text((10, offset + 20), txt, 15))\n",
    "            offset += 20\n",
    "                          \n",
    "        return scene\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SETTINGS = {\n",
    "    'objects': [\n",
    "        'friend',\n",
    "        'enemy',\n",
    "        'boss'\n",
    "    ],\n",
    "    'colors': {\n",
    "        'hero':   'yellow',\n",
    "        'friend': 'green',\n",
    "        'enemy':  'red',\n",
    "        'boss':   'orange',\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'friend': 10,\n",
    "        'enemy': -6,\n",
    "        'boss':  -15,\n",
    "    },\n",
    "    'observation_repr_size': 4,\n",
    "    'observation_repr': {\n",
    "        'friend':  np.array([1,0,0,0]),\n",
    "        'enemy':   np.array([0,1,0,0]),\n",
    "        'boss':    np.array([0,0,1,0]),\n",
    "        'wall':    np.array([0,0,0,1]),\n",
    "        'nothing': np.array([0,0,0,0]),\n",
    "    },\n",
    "    'world_size': (600,400),\n",
    "    'hero_initial_position': [570, 200],\n",
    "    'hero_initial_speed':    [100, 100],\n",
    "    \"object_radius\": 10,\n",
    "    \"num_objects\": {\n",
    "        \"friend\" : 5,\n",
    "        \"enemy\" :  10,\n",
    "        \"boss\" :   5,\n",
    "    },\n",
    "    \"num_observation_lines\" : 16,\n",
    "    \"observation_line_length\": 70,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"actions\": [\n",
    "        [300,  0   ],\n",
    "        [0,    300 ],\n",
    "        [-300, 0   ],\n",
    "        [0,    -300],\n",
    "        [100,  0   ],\n",
    "        [0,    100 ],\n",
    "        [-100, 0   ],\n",
    "        [0,    -100],\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the game simulator\n",
    "g = KarpathyGame(SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# brain maps from observation to action q values. Here it is a simple mlp\n",
    "brain = MLP([g.observation_size,], [100, g.num_actions], [D.MatOps.tanh, lambda x: x])\n",
    "# solver over brian - here simple sgd\n",
    "solver = Solver(brain.parameters(), \"sgd\", learning_rate=0.0001)\n",
    "# DeepQ object\n",
    "c = DeepQ(g.observation_size, g.num_actions, brain, solver, exploration_period=1000, max_experience=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\"?>\n",
       "\n",
       "<svg height=\"500\" width=\"620\" >\n",
       "\n",
       " <g style=\"fill-opacity:1.0; stroke:black;\n",
       "\n",
       "  stroke-width:1;\">\n",
       "\n",
       "  <rect x=\"10\" y=\"10\" height=\"400\"\n",
       "\n",
       "        width=\"600\" style=fill:none; />\n",
       "\n",
       "  <circle cx=\"554\" cy=\"22\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"438\" cy=\"57\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"524\" cy=\"295\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"272\" cy=\"226\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"476\" cy=\"50\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"443\" cy=\"180\" r=\"10\"\n",
       "\n",
       "          style=fill:orange; />\n",
       "\n",
       "  <circle cx=\"80\" cy=\"367\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"414\" cy=\"340\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"181\" cy=\"185\" r=\"10\"\n",
       "\n",
       "          style=fill:orange; />\n",
       "\n",
       "  <circle cx=\"87\" cy=\"187\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"453\" cy=\"308\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"348\" cy=\"342\" r=\"10\"\n",
       "\n",
       "          style=fill:orange; />\n",
       "\n",
       "  <circle cx=\"345\" cy=\"297\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"39\" cy=\"393\" r=\"10\"\n",
       "\n",
       "          style=fill:orange; />\n",
       "\n",
       "  <circle cx=\"310\" cy=\"351\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"460\" cy=\"364\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"404\" cy=\"72\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"444\" cy=\"396\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"422\" cy=\"291\" r=\"10\"\n",
       "\n",
       "          style=fill:orange; />\n",
       "\n",
       "  <circle cx=\"181\" cy=\"392\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"92\" cy=\"297\" r=\"10\"\n",
       "\n",
       "          style=fill:yellow; />\n",
       "\n",
       "  <line x1=\"103\" y1=\"297\" x2=\"172\" y2=\"297\" />\n",
       "\n",
       "  <line x1=\"102\" y1=\"301\" x2=\"165\" y2=\"327\" />\n",
       "\n",
       "  <line x1=\"99\" y1=\"304\" x2=\"148\" y2=\"353\" />\n",
       "\n",
       "  <line x1=\"96\" y1=\"307\" x2=\"122\" y2=\"370\" />\n",
       "\n",
       "  <line x1=\"92\" y1=\"308\" x2=\"92\" y2=\"377\" />\n",
       "\n",
       "  <line x1=\"87\" y1=\"307\" x2=\"61\" y2=\"370\" />\n",
       "\n",
       "  <line x1=\"84\" y1=\"304\" x2=\"35\" y2=\"353\" />\n",
       "\n",
       "  <line x1=\"81\" y1=\"301\" x2=\"18\" y2=\"327\" />\n",
       "\n",
       "  <line x1=\"81\" y1=\"297\" x2=\"12\" y2=\"297\" />\n",
       "\n",
       "  <line x1=\"81\" y1=\"292\" x2=\"18\" y2=\"266\" />\n",
       "\n",
       "  <line x1=\"84\" y1=\"289\" x2=\"35\" y2=\"240\" />\n",
       "\n",
       "  <line x1=\"87\" y1=\"286\" x2=\"61\" y2=\"223\" />\n",
       "\n",
       "  <line x1=\"92\" y1=\"286\" x2=\"91\" y2=\"217\" />\n",
       "\n",
       "  <line x1=\"96\" y1=\"286\" x2=\"122\" y2=\"223\" />\n",
       "\n",
       "  <line x1=\"99\" y1=\"289\" x2=\"148\" y2=\"240\" />\n",
       "\n",
       "  <line x1=\"102\" y1=\"292\" x2=\"165\" y2=\"266\" />\n",
       "\n",
       "  <text x=\"10\" y=\"435\" font-size=\"15\">\n",
       "\n",
       "   DTW        = 72.0\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"455\" font-size=\"15\">\n",
       "\n",
       "   experience = 11483\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"475\" font-size=\"15\">\n",
       "\n",
       "   reward = -0.2\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"495\" font-size=\"15\">\n",
       "\n",
       "   objects eaten => friend: 990, boss: 506, enemy: 1105\n",
       "\n",
       "  </text>\n",
       "\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<svg.Scene at 0x7fb15dd60828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-391ba9a829d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0meq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimulation_resultion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_per_second\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspeed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_every_nth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-119-391ba9a829d3>\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(game, controller, fps, actions_per_second, simulation_resultion, speed, store_every_nth)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0meq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule_recurring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_between_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0meq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimulation_resultion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_per_second\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspeed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_every_nth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sidor/projects/dali-deepq/event_queue.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnow\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def simulate(game,\n",
    "             controller,\n",
    "             fps=60,\n",
    "             actions_per_second=60,\n",
    "             simulation_resultion=0.001,\n",
    "             speed=1.0,\n",
    "             store_every_nth=5):\n",
    "    \"\"\"Start the simulation. Performs three tasks\n",
    "       \n",
    "        - visualizes simulation in iPython notebook\n",
    "        - advances game simulator state\n",
    "        - reports state to controller and chooses actions\n",
    "          to be performed.\n",
    "    \"\"\"\n",
    "    eq = EventQueue()\n",
    "    \n",
    "    time_between_frames  = 1.0 / fps\n",
    "    time_between_actions = 1.0 / (actions_per_second * speed)\n",
    "    \n",
    "    def visualize():\n",
    "        clear_output(wait=True)\n",
    "        recent_reward = game.collected_rewards[-100:] + [0]\n",
    "        objects_eaten_str = ', '.join([\"%s: %s\" % (o,c) for o,c in game.objects_eaten.items()])\n",
    "        display(game.to_html([\n",
    "            \"DTW        = %.1f\" % (game.distance_to_walls(),),\n",
    "            \"experience = %d\" % (len(controller.experience),),\n",
    "            \"reward = %.1f\" % (sum(recent_reward)/len(recent_reward),),\n",
    "            \"objects eaten => %s\" % (objects_eaten_str,),\n",
    "\n",
    "        ]))\n",
    "    eq.schedule_recurring(visualize, time_between_frames)\n",
    "        \n",
    "    simulated_up_to = time.time()\n",
    "\n",
    "    def simulate_game():\n",
    "        nonlocal simulated_up_to\n",
    "        now = time.time()\n",
    "        time_to_be_simulated = speed * (now - simulated_up_to)\n",
    "        for _ in range(int(time_to_be_simulated / simulation_resultion)):\n",
    "            game.step(simulation_resultion)\n",
    "        simulated_up_to = now\n",
    "        \n",
    "    eq.schedule_recurring(simulate_game, min(time_between_frames, time_between_actions))\n",
    "\n",
    "    \n",
    "    last_observation = None\n",
    "    last_action      = None\n",
    "    actions_so_far = 0\n",
    "    \n",
    "    def control():\n",
    "        nonlocal last_observation\n",
    "        nonlocal last_action\n",
    "        nonlocal actions_so_far\n",
    "        # sense\n",
    "        new_observation = game.observe()\n",
    "        reward          = game.collect_reward()\n",
    "        # store last transition\n",
    "        actions_so_far += 1\n",
    "        if last_observation is not None and actions_so_far % store_every_nth == 0:\n",
    "            controller.store(last_observation, last_action, reward, new_observation)\n",
    "        # act\n",
    "        new_action = controller.action(new_observation)\n",
    "        game.perform_action(new_action)\n",
    "        last_action = new_action\n",
    "        last_observation = new_observation\n",
    "        \n",
    "        #train\n",
    "        controller.training_step()\n",
    "        \n",
    "    \n",
    "    eq.schedule_recurring(control, time_between_actions)\n",
    "    \n",
    "    eq.run()\n",
    "    \n",
    "simulate(g, c, fps = 30, simulation_resultion=0.01, actions_per_second=15, speed=1.0, store_every_nth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCGEEEIIIYQQQggh4vH/AS3rvvs9Jv4xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1613905c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.plot_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIiK5/D/vBKZqars7FQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb15ee2f8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.plot_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
