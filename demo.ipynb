{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output, display, HTML\n",
    "from euclid import Circle, Point2, Vector2, LineSegment2\n",
    "\n",
    "import svg\n",
    "\n",
    "from event_queue import EventQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class DeepQ(object):\n",
    "    def __init__(self, observation_size,\n",
    "                       num_actions,\n",
    "                       observation_to_actions,\n",
    "                       solver,\n",
    "                       random_action_probability=0.05,\n",
    "                       exploration_period=1000,\n",
    "                       minibatch_size=32,\n",
    "                       discount_rate=0.95,\n",
    "                       max_experience=30000):\n",
    "        \"\"\"Initialized the Deepq object.\n",
    "        \n",
    "        Based on:\n",
    "            https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "            \n",
    "        Parameters\n",
    "        -------\n",
    "        observation_size : int\n",
    "            length of the vector passed as observation\n",
    "        num_actions : int\n",
    "            number of actions that the model can execute\n",
    "        observation_to_actions: dali model\n",
    "            model that implements activate function\n",
    "            that can take in observation vector or a batch\n",
    "            and returns scores (of unbounded values) for each\n",
    "            action for each observation.\n",
    "            input shape:  [batch_size, observation_size]\n",
    "            output shape: [batch_size, num_actions]\n",
    "        solver: dali solver\n",
    "            solver over observation_to_actions,\n",
    "            must implement the step function\n",
    "        random_action_probability: float (0 to 1)\n",
    "        exploration_period: int\n",
    "            probability of choosing a random \n",
    "            action (epsilon form paper) annealed linearly\n",
    "            from 1 to random_action_probability over\n",
    "            exploration_period\n",
    "        minibatch_size: int\n",
    "            number of state,action,reward,newstate\n",
    "            tuples considered during experience reply\n",
    "        dicount_rate: float (0 to 1)\n",
    "            how much we care about future rewards.\n",
    "        max_experience: int\n",
    "            maximum size of the reply buffer\n",
    "        \"\"\"\n",
    "        # memorize arguments\n",
    "        self.observation_size          = observation_size\n",
    "        self.num_actions               = num_actions\n",
    "        \n",
    "        self.observation_to_actions    = observation_to_actions\n",
    "        self.solver                    = solver\n",
    "        \n",
    "        self.random_action_probability = random_action_probability\n",
    "        self.exploration_period        = exploration_period\n",
    "        self.minibatch_size            = minibatch_size\n",
    "        self.discount_rate             = discount_rate\n",
    "        self.max_experience            = max_experience\n",
    "        \n",
    "        # deepq state\n",
    "        self.actions_executed_so_far = 0\n",
    "        self.experience = deque()\n",
    "        \n",
    "        self.error_history = []\n",
    "        \n",
    "    def linear_annealing(self, n, total, p_initial, p_final):\n",
    "        \"\"\"Linear annealing between p_initial and p_final\n",
    "        over total steps - computes value at step n\"\"\"\n",
    "        if n >= total:\n",
    "            return p_final\n",
    "        else:\n",
    "            return p_initial - (n * (p_initial - p_final)) / (total)\n",
    "\n",
    "    def activate(self, observation):\n",
    "        \"\"\"Given observation or a batch returns action scores.\"\"\"\n",
    "        action_scores = self.observation_to_actions.activate(observation)\n",
    "        assert action_scores.shape[1] == self.num_actions, \\\n",
    "                \"number of columns in the output of `observation_to_actions` must be equal to number of actions.\"\n",
    "        assert action_scores.shape[0] == observation.shape[0], \\\n",
    "                \"number of output rows of `observation_to_actions` must be equal to number of input rows\"\n",
    "        return action_scores\n",
    "    \n",
    "    def action(self, observation):\n",
    "        \"\"\"Given observation returns the action that should be chosen using\n",
    "        DeepQ learning strategy. Does not backprop.\"\"\"\n",
    "        assert len(observation.shape) == 1, \\\n",
    "                \"Action is performed based on single observation.\"\n",
    "\n",
    "        self.actions_executed_so_far += 1\n",
    "        exploration_p = self.linear_annealing(self.actions_executed_so_far,\n",
    "                                              self.exploration_period,\n",
    "                                              1.0,\n",
    "                                              self.random_action_probability)\n",
    "                                                 \n",
    "        if random.random() < exploration_p:\n",
    "            return random.randint(0, self.num_actions - 1)\n",
    "        else:\n",
    "            with D.NoBackprop():\n",
    "                observation_dali = D.Mat(observation[np.newaxis,:], constant=True)\n",
    "                assert observation_dali.shape == (1, observation.shape[0])\n",
    "                action_scores = self.activate(observation_dali)\n",
    "                return D.MatOps.argmax(action_scores, axis=1)[0]\n",
    "        \n",
    "    def store(self, observation, action, reward, newobservation):\n",
    "        \"\"\"Store experience, where starting with observation and\n",
    "        execution action, we arrived at the newobservation and got the\n",
    "        reward reward\n",
    "        \n",
    "        If newstate is None, the state/action pair is assumed to be terminal\n",
    "        \"\"\"\n",
    "        self.experience.append((observation, action, reward, newobservation))\n",
    "        if len(self.experience) > self.max_experience:\n",
    "            self.experience.popleft()\n",
    "    \n",
    "    def training_step(self):\n",
    "        \"\"\"Pick a self.minibatch_size exeperiences from reply buffer\n",
    "        and backpropage the value function.\n",
    "        \"\"\"\n",
    "        if len(self.experience) <  self.minibatch_size:\n",
    "            return\n",
    "        \n",
    "        # sample experience. \n",
    "        samples   = random.sample(range(len(self.experience)), self.minibatch_size)\n",
    "        samples   = [self.experience[i] for i in samples]\n",
    "        \n",
    "        # bach states\n",
    "        states    = np.empty((len(samples), self.observation_size))\n",
    "        newstates = np.empty((len(samples), self.observation_size))\n",
    "        action_mask    = np.zeros((len(samples), self.num_actions))\n",
    "        \n",
    "        newstates_mask = np.empty((len(samples),))\n",
    "        rewards        = np.empty((len(samples),))\n",
    "        \n",
    "        for i, (state, action, reward, newstate) in enumerate(samples):\n",
    "            states[i] = state\n",
    "            action_mask[i] = 0\n",
    "            action_mask[i][action] = 1\n",
    "            rewards[i] = reward\n",
    "            if newstate is not None:\n",
    "                newstates[i] = state\n",
    "                newstates_mask[i] = 1\n",
    "            else:\n",
    "                newstates[i] = 0\n",
    "                newstates_mask[i] = 0\n",
    "                \n",
    "        # convert to dali, steal numpy memory, do not compute gradient (that's constant)\n",
    "        states      = D.Mat(states,      borrow=True, constant=True)\n",
    "        newstates   = D.Mat(newstates,   borrow=True, constant=True)\n",
    "        action_mask = D.Mat(action_mask, borrow=True, constant=True)\n",
    "        \n",
    "        # compute target value functions\n",
    "        with D.NoBackprop():\n",
    "            action_scores = self.activate(newstates)\n",
    "        # rowwise max - best achievable value function for each sample.\n",
    "        newstates_value = action_scores.w.max(axis=1) * newstates_mask\n",
    "        targets = rewards + self.discount_rate * newstates_value\n",
    "\n",
    "        # convert to dali, steal numpy memory, do not compute gradient (that's constant)\n",
    "        targets     = D.Mat(targets,     borrow=True, constant=True)\n",
    "        \n",
    "        # this computation will be backpropagated.\n",
    "        action_scores = self.activate(states)\n",
    "        relevant_actions = (action_scores * action_mask).sum(axis=1)\n",
    "        error = (relevant_actions - targets)**2\n",
    "        error.grad()\n",
    "        \n",
    "        # compute gradient\n",
    "        D.Graph.backward()\n",
    "        # apply gradient\n",
    "        solver.step()\n",
    "        \n",
    "        self.error_history.append(float(error.w.sum() / len(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "class GameObject(object):\n",
    "    def __init__(self, position, speed, obj_type, settings):\n",
    "        \"\"\"Esentially represents circles of different kinds, which have\n",
    "        position and speed.\"\"\"\n",
    "        self.settings = settings\n",
    "        self.radius = self.settings[\"object_radius\"]\n",
    "        \n",
    "        self.obj_type = obj_type\n",
    "        self.position = position\n",
    "        self.speed    = speed\n",
    "        self.bounciness = 1.0\n",
    "                \n",
    "    def wall_collisions(self):\n",
    "        \"\"\"Update speed upon collision with the wall.\"\"\"\n",
    "        world_size = self.settings[\"world_size\"]\n",
    "\n",
    "        for dim in range(2):\n",
    "            if self.position[dim] - self.radius       <= 0               and self.speed[dim] < 0:\n",
    "                self.speed[dim] = - self.speed[dim] * self.bounciness\n",
    "            elif self.position[dim] + self.radius + 1 >= world_size[dim] and self.speed[dim] > 0:\n",
    "                self.speed[dim] = - self.speed[dim] * self.bounciness\n",
    "        \n",
    "    def move(self, dt):\n",
    "        \"\"\"Move as if dt seconds passed\"\"\"\n",
    "        self.position += dt * self.speed\n",
    "        self.position = Point2(*self.position)\n",
    "        \n",
    "    def step(self, dt):\n",
    "        \"\"\"Move and bounce of walls.\"\"\"\n",
    "        self.wall_collisions()\n",
    "        self.move(dt)\n",
    "        \n",
    "    def as_circle(self):\n",
    "        return Circle(self.position, float(self.radius))\n",
    "        \n",
    "    def draw(self):\n",
    "        \"\"\"Return svg object for this item.\"\"\"\n",
    "        color = self.settings[\"colors\"][self.obj_type]\n",
    "        return svg.Circle(self.position + Point2(10, 10), self.radius, color=color)\n",
    "\n",
    "class KarpathyGame(object):\n",
    "    def __init__(self, settings):\n",
    "        \"\"\"Initiallize game simulator with settings\"\"\"\n",
    "        self.settings = settings\n",
    "        self.size  = self.settings[\"world_size\"]\n",
    "        self.walls = [LineSegment2(Point2(0,0),                        Point2(0,self.size[1])),\n",
    "                      LineSegment2(Point2(0,self.size[1]),             Point2(self.size[0], self.size[1])),\n",
    "                      LineSegment2(Point2(self.size[0], self.size[1]), Point2(self.size[0], 0)),\n",
    "                      LineSegment2(Point2(self.size[0], 0),            Point2(0,0))]\n",
    "        \n",
    "        self.hero = GameObject(Point2(*self.settings[\"hero_initial_position\"]),\n",
    "                               Vector2(*self.settings[\"hero_initial_speed\"]),\n",
    "                               \"hero\",\n",
    "                               self.settings)\n",
    "        if not self.settings[\"hero_bounces_off_walls\"]:\n",
    "            self.hero.bounciness = 0.0\n",
    "        \n",
    "        self.objects = []\n",
    "        for obj_type, number in settings[\"num_objects\"].items():\n",
    "            for _ in range(number):\n",
    "                self.spawn_object(obj_type)\n",
    "        \n",
    "        self.observation_lines = self.generate_observation_lines()\n",
    "                \n",
    "        self.object_reward = 0\n",
    "        self.collected_rewards = []\n",
    "        \n",
    "        # every observation_line sees one of objects or wall and\n",
    "        # two numbers representing speed of the object (if applicable)\n",
    "        self.eye_observation_size = len(self.settings[\"objects\"]) + 3\n",
    "        # additionally there are two numbers representing agents own speed.\n",
    "        self.observation_size = self.eye_observation_size * len(self.observation_lines) + 2\n",
    "        \n",
    "        self.directions = [Vector2(*d) for d in [[1,0], [0,1], [-1,0],[0,-1]]]\n",
    "        self.num_actions      = len(self.directions)\n",
    "        \n",
    "        self.objects_eaten = defaultdict(lambda: 0)\n",
    "        \n",
    "    def perform_action(self, action_id):\n",
    "        \"\"\"Change speed to one of hero vectors\"\"\"\n",
    "        assert 0 <= action_id < self.num_actions\n",
    "        self.hero.speed *= 0.8\n",
    "        self.hero.speed += self.directions[action_id] * self.settings[\"delta_v\"]\n",
    "            \n",
    "    def spawn_object(self, obj_type):\n",
    "        \"\"\"Spawn object of a given type and add it to the objects array\"\"\"\n",
    "        radius = self.settings[\"object_radius\"]\n",
    "        position = np.random.uniform([radius, radius], np.array(self.size) - radius)\n",
    "        position = Point2(float(position[0]), float(position[1]))\n",
    "        max_speed = np.array(self.settings[\"maximum_speed\"])\n",
    "        speed    = np.random.uniform(-max_speed, max_speed).astype(float)\n",
    "        speed = Vector2(float(speed[0]), float(speed[1]))\n",
    "\n",
    "        self.objects.append(GameObject(position, speed, obj_type, self.settings))     \n",
    "                \n",
    "    def step(self, dt):\n",
    "        \"\"\"Simulate all the objects for a given ammount of time.\n",
    "        \n",
    "        Also resolve collisions with the hero\"\"\"\n",
    "        for obj in self.objects + [self.hero] :\n",
    "            obj.step(dt)\n",
    "        self.resolve_collisions()\n",
    "\n",
    "    def squared_distance(self, p1, p2):\n",
    "        return (p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2\n",
    "        \n",
    "    def resolve_collisions(self):\n",
    "        \"\"\"If hero touches, hero eats. Also reward gets updated.\"\"\"\n",
    "        collision_distance = 2 * self.settings[\"object_radius\"]\n",
    "        collision_distance2 = collision_distance ** 2\n",
    "        to_remove = []\n",
    "        for obj in self.objects:\n",
    "            if self.squared_distance(self.hero.position, obj.position) < collision_distance2:\n",
    "                to_remove.append(obj)\n",
    "        for obj in to_remove:\n",
    "            self.objects.remove(obj)\n",
    "            self.objects_eaten[obj.obj_type] += 1\n",
    "            self.object_reward += self.settings[\"object_reward\"][obj.obj_type]\n",
    "            self.spawn_object(obj.obj_type)\n",
    "        \n",
    "    def inside_walls(self, point):\n",
    "        \"\"\"Check if the point is inside the walls\"\"\"\n",
    "        EPS = 1e-4\n",
    "        return (EPS <= point[0] < self.size[0] - EPS and\n",
    "                EPS <= point[1] < self.size[1] - EPS)\n",
    "        \n",
    "    def observe(self):\n",
    "        \"\"\"Return observation vector. For all the observation directions it returns representation\n",
    "        of the closest object to the hero - might be nothing, another object or a wall.\n",
    "        Representation of observation for all the directions will be concatenated.\n",
    "        \"\"\"\n",
    "        num_obj_types = len(self.settings[\"objects\"]) + 1 # and wall\n",
    "        max_speed_x, max_speed_y = self.settings[\"maximum_speed\"]\n",
    "        \n",
    "        observable_distance = self.settings[\"observation_line_length\"]\n",
    "        \n",
    "        relevant_objects = [obj for obj in self.objects \n",
    "                            if obj.position.distance(self.hero.position) < observable_distance]\n",
    "        # objects sorted from closest to furthest\n",
    "        relevant_objects.sort(key=lambda x: x.position.distance(self.hero.position))\n",
    "        \n",
    "        observation        = np.zeros(self.observation_size)\n",
    "        observation_offset = 0 \n",
    "        for i, observation_line in enumerate(self.observation_lines):\n",
    "            # shift to hero position\n",
    "            observation_line = LineSegment2(self.hero.position + Vector2(*observation_line.p1),\n",
    "                                            self.hero.position + Vector2(*observation_line.p2))\n",
    "\n",
    "            observed_object = None\n",
    "            # if end of observation line is outside of walls, we see the wall.\n",
    "            if not self.inside_walls(observation_line.p2):\n",
    "                observed_object = \"**wall**\"\n",
    "            for obj in relevant_objects:\n",
    "                if observation_line.distance(obj.position) < self.settings[\"object_radius\"]:\n",
    "                    observed_object = obj\n",
    "                    break\n",
    "            object_type_id = None\n",
    "            speed_x, speed_y = 0, 0\n",
    "            proximity = 0\n",
    "            if observed_object == \"**wall**\": # wall seen \n",
    "                object_type_id = num_obj_types - 1\n",
    "                # a wall has fairly low speed...\n",
    "                speed_x, speed_y = 0, 0\n",
    "                # best candidate is intersection between\n",
    "                # observation_line and a wall, that's\n",
    "                # closest to the hero\n",
    "                best_candidate = None\n",
    "                for wall in self.walls:\n",
    "                    candidate = observation_line.intersect(wall)\n",
    "                    if candidate is not None:\n",
    "                        if (best_candidate is None or \n",
    "                                best_candidate.distance(self.hero.position) >\n",
    "                                candidate.distance(self.hero.position)):\n",
    "                            best_candidate = candidate\n",
    "                if best_candidate is None:\n",
    "                    # assume it is due to rounding errors\n",
    "                    # and wall is barely touching observation line\n",
    "                    proximity = observable_distance\n",
    "                else:\n",
    "                    proximity = best_candidate.distance(self.hero.position)\n",
    "            elif observed_object is not None: # agent seen\n",
    "                object_type_id = self.settings[\"objects\"].index(observed_object.obj_type)\n",
    "                speed_x, speed_y = tuple(observed_object.speed)\n",
    "                intersection_segment = obj.as_circle().intersect(observation_line)\n",
    "                assert intersection_segment is not None\n",
    "                proximity = min(intersection_segment.p1.distance(self.hero.position),\n",
    "                                intersection_segment.p2.distance(self.hero.position))\n",
    "            for object_type_idx_loop in range(num_obj_types):\n",
    "                observation[observation_offset + object_type_idx_loop] = 1.0\n",
    "            if object_type_id is not None:\n",
    "                observation[observation_offset + object_type_id] = proximity / observable_distance\n",
    "            observation[observation_offset + num_obj_types] =     speed_x   / max_speed_x\n",
    "            observation[observation_offset + num_obj_types + 1] = speed_y   / max_speed_y\n",
    "            assert num_obj_types + 2 == self.eye_observation_size\n",
    "            observation_offset += self.eye_observation_size\n",
    "        \n",
    "        observation[observation_offset]     = self.hero.speed[0] / max_speed_x\n",
    "        observation[observation_offset + 1] = self.hero.speed[1] / max_speed_y\n",
    "        assert observation_offset + 2 == self.observation_size\n",
    "        \n",
    "        return observation        \n",
    "    \n",
    "    def distance_to_walls(self):\n",
    "        \"\"\"Returns distance of a hero to walls\"\"\"\n",
    "        res = float('inf')\n",
    "        for wall in self.walls:\n",
    "            res = min(res, self.hero.position.distance(wall))\n",
    "        return res - self.settings[\"object_radius\"]\n",
    "        \n",
    "    def collect_reward(self):\n",
    "        \"\"\"Return accumulated object eating score + current distance to walls score\"\"\"\n",
    "        wall_reward =  self.settings[\"wall_distance_penalty\"] * \\\n",
    "                       np.exp(-self.distance_to_walls() / self.settings[\"tolerable_distance_to_wall\"])\n",
    "        assert wall_reward < 1e-3, \"You are rewarding hero for being close to the wall!\"\n",
    "        total_reward = wall_reward + self.object_reward\n",
    "        self.object_reward = 0\n",
    "        self.collected_rewards.append(total_reward)\n",
    "        return total_reward\n",
    "        \n",
    "    def plot_reward(self, smoothing = 30):\n",
    "        \"\"\"Plot evolution of reward over time.\"\"\"\n",
    "        plottable = self.collected_rewards[:]\n",
    "        while len(plottable) > 1000:\n",
    "            for i in range(0, len(plottable) - 1, 2):\n",
    "                plottable[i//2] = (plottable[i] + plottable[i+1]) / 2\n",
    "            plottable = plottable[:(len(plottable) // 2)]\n",
    "        x = []\n",
    "        for  i in range(smoothing, len(plottable)):\n",
    "            chunk = plottable[i-smoothing:i]\n",
    "            x.append(sum(chunk) / len(chunk))\n",
    "        plt.plot(list(range(len(x))), x)\n",
    "        \n",
    "    def generate_observation_lines(self):\n",
    "        \"\"\"Generate observation segments in settings[\"num_observation_lines\"] directions\"\"\"\n",
    "        result = []\n",
    "        start = Point2(0.0, 0.0)\n",
    "        end   = Point2(self.settings[\"observation_line_length\"],\n",
    "                       self.settings[\"observation_line_length\"])\n",
    "        for angle in np.linspace(0, 2*np.pi, self.settings[\"num_observation_lines\"], endpoint=False):\n",
    "            rotation = Point2(math.cos(angle), math.sin(angle))\n",
    "            current_start = Point2(start[0] * rotation[0], start[1] * rotation[1])\n",
    "            current_end   = Point2(end[0]   * rotation[0], end[1]   * rotation[1])\n",
    "            result.append( LineSegment2(current_start, current_end))\n",
    "        return result\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return self.to_html()\n",
    "    \n",
    "    def to_html(self, stats=[]):\n",
    "        \"\"\"Return svg representation of the simulator\"\"\"\n",
    "        scene = svg.Scene((self.size[0] + 20, self.size[1] + 20 + 20 * len(stats)))\n",
    "        scene.add(svg.Rectangle((10, 10), self.size))\n",
    "\n",
    "            \n",
    "        for line in self.observation_lines:\n",
    "            scene.add(svg.Line(line.p1 + self.hero.position + Point2(10,10),\n",
    "                               line.p2 + self.hero.position + Point2(10,10)))\n",
    "        \n",
    "        for obj in self.objects + [self.hero] :\n",
    "            scene.add(obj.draw())\n",
    "        \n",
    "        offset = self.size[1] + 15\n",
    "        for txt in stats:              \n",
    "            scene.add(svg.Text((10, offset + 20), txt, 15))\n",
    "            offset += 20\n",
    "                          \n",
    "        return scene\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulate(game,\n",
    "             controller,\n",
    "             fps=60,\n",
    "             actions_per_game_second=60,\n",
    "             simulation_resultion=0.001,\n",
    "             speed=1.0,\n",
    "             store_every_nth=5,\n",
    "             train_every_nth=5):\n",
    "    \"\"\"Start the simulation. Performs three tasks\n",
    "       \n",
    "        - visualizes simulation in iPython notebook\n",
    "        - advances game simulator state\n",
    "        - reports state to controller and chooses actions\n",
    "          to be performed.\n",
    "    \"\"\"\n",
    "    eq = EventQueue()\n",
    "    \n",
    "    time_between_frames  = 1.0 / fps\n",
    "    game_time_between_actions = 1.0 / actions_per_game_second\n",
    "    \n",
    "    simulation_resultion /= speed\n",
    "    \n",
    "    ###### VISUALIZATION\n",
    "    def visualize():\n",
    "        recent_reward = game.collected_rewards[-100:] + [0]\n",
    "        objects_eaten_str = ', '.join([\"%s: %s\" % (o,c) for o,c in game.objects_eaten.items()])\n",
    "        clear_output(wait=True)\n",
    "        display(game.to_html([\n",
    "            \"DTW        = %.1f\" % (game.distance_to_walls(),),\n",
    "            \"experience = %d\" % (len(controller.experience),),\n",
    "            \"reward = %.1f\" % (sum(recent_reward)/len(recent_reward),),\n",
    "            \"objects eaten => %s\" % (objects_eaten_str,),\n",
    "\n",
    "        ]))\n",
    "    eq.schedule_recurring(visualize, time_between_frames)\n",
    "\n",
    "    \n",
    "    ###### CONTROL\n",
    "    ctrl_s = {\n",
    "        'last_observation': None,\n",
    "        'last_action':      None,\n",
    "        'actions_so_far':   0,\n",
    "    }\n",
    "    \n",
    "    def control():\n",
    "        # sense\n",
    "        new_observation = game.observe()\n",
    "        reward          = game.collect_reward()\n",
    "        # store last transition\n",
    "        ctrl_s['actions_so_far'] += 1\n",
    "        if ctrl_s['last_observation'] is not None and ctrl_s['actions_so_far'] % store_every_nth == 0:\n",
    "            controller.store(ctrl_s['last_observation'], ctrl_s['last_action'], reward, new_observation)\n",
    "        # act\n",
    "        new_action = controller.action(new_observation)\n",
    "        game.perform_action(new_action)\n",
    "        ctrl_s['last_action'] = new_action\n",
    "        ctrl_s['last_observation'] = new_observation\n",
    "        \n",
    "        #train\n",
    "        if  ctrl_s['last_observation'] is not None and ctrl_s['actions_so_far'] % train_every_nth == 0:\n",
    "            controller.training_step()\n",
    "    \n",
    "    ##### SIMULATION\n",
    "    sim_s = {\n",
    "        'simulated_up_to':             time.time(),\n",
    "        'game_time_since_last_action': 0,\n",
    "    }\n",
    "    def simulate_game():\n",
    "        while sim_s['simulated_up_to'] < time.time():\n",
    "            game.step(simulation_resultion)\n",
    "            sim_s['simulated_up_to'] += simulation_resultion / speed\n",
    "            sim_s['game_time_since_last_action'] += simulation_resultion\n",
    "            if sim_s['game_time_since_last_action'] > game_time_between_actions:\n",
    "                control()\n",
    "                sim_s['game_time_since_last_action'] = 0\n",
    "        \n",
    "    eq.schedule_recurring(simulate_game, time_between_frames)\n",
    "    \n",
    "    eq.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_settings = {\n",
    "    'objects': [\n",
    "        'friend',\n",
    "        'enemy',\n",
    "#         'boss'\n",
    "    ],\n",
    "    'colors': {\n",
    "        'hero':   'yellow',\n",
    "        'friend': 'green',\n",
    "        'enemy':  'red',\n",
    "#         'boss':   'orange',\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'friend': 1,\n",
    "        'enemy': -1,\n",
    "#         'boss':  -20,\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (700,500),\n",
    "    'hero_initial_position': [400, 300],\n",
    "    'hero_initial_speed':    [0,   0],\n",
    "    \"maximum_speed\":         [50, 50],\n",
    "    \"object_radius\": 10.0,\n",
    "    \"num_objects\": {\n",
    "        \"friend\" : 25,\n",
    "        \"enemy\" :  25,\n",
    "#         \"boss\" :   5,\n",
    "    },\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 120.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -0.0,\n",
    "    \"delta_v\": 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# brain maps from observation to action q values. Here it is a simple mlp\n",
    "brain = MLP([g.observation_size,], [100, g.num_actions], \n",
    "            [activation.tanh, activation.identity])\n",
    "# solver over brian - here simple sgd\n",
    "solver = Solver(brain.parameters(), \"rmsprop\", learning_rate= 0.005)\n",
    "# solver = Solver(brain.parameters(), \"sgd\", learning_rate= 0.001)\n",
    "\n",
    "# DeepQ object\n",
    "current_controller = DeepQ(g.observation_size, g.num_actions, brain, solver,\n",
    "                           discount_rate=0.9, exploration_period=5000, max_experience=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "CONTROLLER_PATH = \"controller.pkz\"\n",
    "SETTINGS_PATH   = \"settings.json\"\n",
    "\n",
    "def save():\n",
    "    with open(SETTINGS_PATH, \"w\") as f:\n",
    "        json.dump(current_settings, f)\n",
    "    with open(CONTROLLER_PATH, \"wb\") as f:\n",
    "        pickle.dump(current_controller, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT FOR WSAD CONTROL (requires redis server to be running, commands can be sent from terminal)\n",
    "from human_control import HumanController\n",
    "current_controller = HumanController({b\"w\": 3, b\"d\": 0, b\"s\": 1,b\"a\": 2,}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\"?>\n",
       "\n",
       "<svg height=\"600\" width=\"720\" >\n",
       "\n",
       " <g style=\"fill-opacity:1.0; stroke:black;\n",
       "\n",
       "  stroke-width:1;\">\n",
       "\n",
       "  <rect x=\"10\" y=\"10\" height=\"500\"\n",
       "\n",
       "        width=\"700\" style=fill:none; />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"343\" y2=\"152\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"340\" y2=\"176\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"334\" y2=\"198\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"322\" y2=\"219\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"308\" y2=\"237\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"289\" y2=\"252\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"269\" y2=\"263\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"246\" y2=\"270\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"223\" y2=\"272\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"199\" y2=\"270\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"177\" y2=\"263\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"156\" y2=\"252\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"138\" y2=\"237\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"123\" y2=\"219\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"112\" y2=\"198\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"105\" y2=\"176\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"103\" y2=\"152\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"105\" y2=\"129\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"112\" y2=\"106\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"123\" y2=\"86\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"138\" y2=\"67\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"156\" y2=\"52\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"177\" y2=\"41\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"199\" y2=\"35\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"223\" y2=\"32\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"246\" y2=\"35\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"269\" y2=\"41\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"289\" y2=\"52\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"308\" y2=\"67\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"322\" y2=\"86\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"334\" y2=\"106\" />\n",
       "\n",
       "  <line x1=\"223\" y1=\"152\" x2=\"340\" y2=\"129\" />\n",
       "\n",
       "  <circle cx=\"237\" cy=\"426\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"387\" cy=\"241\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"187\" cy=\"352\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"527\" cy=\"412\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"492\" cy=\"478\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"555\" cy=\"299\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"103\" cy=\"279\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"216\" cy=\"275\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"291\" cy=\"176\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"484\" cy=\"418\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"387\" cy=\"355\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"538\" cy=\"96\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"409\" cy=\"45\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"316\" cy=\"482\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"372\" cy=\"353\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"412\" cy=\"237\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"258\" cy=\"461\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"481\" cy=\"308\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"453\" cy=\"176\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"170\" cy=\"42\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"303\" cy=\"235\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"243\" cy=\"458\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"518\" cy=\"305\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"588\" cy=\"130\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"383\" cy=\"354\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"141\" cy=\"352\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"476\" cy=\"281\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"188\" cy=\"427\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"156\" cy=\"397\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"567\" cy=\"87\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"460\" cy=\"392\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"249\" cy=\"391\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"351\" cy=\"207\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"256\" cy=\"456\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"72\" cy=\"228\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"557\" cy=\"327\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"517\" cy=\"433\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"72\" cy=\"366\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"464\" cy=\"473\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"461\" cy=\"445\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"207\" cy=\"367\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"169\" cy=\"40\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"386\" cy=\"178\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"314\" cy=\"45\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"378\" cy=\"323\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"224\" cy=\"237\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"471\" cy=\"203\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"456\" cy=\"462\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"189\" cy=\"408\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"208\" cy=\"117\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"223\" cy=\"152\" r=\"10\"\n",
       "\n",
       "          style=fill:yellow; />\n",
       "\n",
       "  <text x=\"10\" y=\"535\" font-size=\"15\">\n",
       "\n",
       "   DTW        = 132.7\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"555\" font-size=\"15\">\n",
       "\n",
       "   experience = 0\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"575\" font-size=\"15\">\n",
       "\n",
       "   reward = 0.0\n",
       "\n",
       "  </text>\n",
       "\n",
       "  <text x=\"10\" y=\"595\" font-size=\"15\">\n",
       "\n",
       "   objects eaten => enemy: 16, friend: 39\n",
       "\n",
       "  </text>\n",
       "\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<svg.Scene instance at 0x7f1381d11878>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.__class__ = KarpathyGame\n",
    "# THE LINE BELOW IS FOR FAST LEARNING\n",
    "# FPS, SPEED, RES = 1, 4.5, 0.1\n",
    "# THE LINE BELOW IS FOR REAL TIME VISUALIZATION\n",
    "FPS, SPEED, RES = 30, 1., 0.03\n",
    "\n",
    "simulate(g, current_controller, fps = FPS,\n",
    "         simulation_resultion=RES,\n",
    "         actions_per_game_second=10,\n",
    "         speed=SPEED,\n",
    "         store_every_nth=4,\n",
    "         train_every_nth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Reward over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3bc5e1ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.plot_reward(smoothing=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training error over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3b95ca198>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEACAYAAABCl1qQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3bc631278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = median_smoothing(current_controller.error_history[::8], 1000)\n",
    "x = range(len(y))\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing what the agent is seeing\n",
    "\n",
    "Starting with the ray pointing all the way right, we have one row per ray in clockwise order.\n",
    "The numbers for each ray are the following:\n",
    "- first three numbers are normalized distances to the closest visible (intersecting with the ray) object. If no object is visible then all of them are $1$. If there's many objects in sight, then only the closest one is visible. The numbers represent distance to friend, enemy and wall in order.\n",
    "- the last two numbers represent the speed of moving object (x and y components). Speed of wall is ... zero.\n",
    "\n",
    "Finally the last two numbers in the representation correspond to speed of the hero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00 0.55 1.00 0.49 -0.66]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [0.34 1.00 1.00 0.18 0.01]\n",
      " [0.34 1.00 1.00 0.18 0.01]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 0.22 0.00 0.00]\n",
      " [1.00 1.00 0.11 0.00 0.00]\n",
      " [1.00 1.00 0.08 0.00 0.00]\n",
      " [1.00 1.00 0.06 0.00 0.00]\n",
      " [1.00 1.00 0.05 0.00 0.00]\n",
      " [1.00 1.00 0.05 0.00 0.00]\n",
      " [1.00 1.00 0.04 0.00 0.00]\n",
      " [1.00 1.00 0.04 0.00 0.00]\n",
      " [1.00 1.00 0.04 0.00 0.00]\n",
      " [1.00 1.00 0.05 0.00 0.00]\n",
      " [1.00 1.00 0.05 0.00 0.00]\n",
      " [1.00 1.00 0.06 0.00 0.00]\n",
      " [1.00 1.00 0.08 0.00 0.00]\n",
      " [1.00 1.00 0.11 0.00 0.00]\n",
      " [1.00 1.00 0.22 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [0.77 1.00 1.00 -0.65 -0.11]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 1.00 1.00 0.00 0.00]\n",
      " [1.00 0.54 1.00 0.49 -0.66]]\n",
      "[0.00 0.11]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\"?>\n",
       "\n",
       "<svg height=\"520\" width=\"720\" >\n",
       "\n",
       " <g style=\"fill-opacity:1.0; stroke:black;\n",
       "\n",
       "  stroke-width:1;\">\n",
       "\n",
       "  <rect x=\"10\" y=\"10\" height=\"500\"\n",
       "\n",
       "        width=\"700\" style=fill:none; />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"135\" y2=\"228\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"132\" y2=\"252\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"125\" y2=\"274\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"114\" y2=\"295\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"99\" y2=\"313\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"81\" y2=\"328\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"60\" y2=\"339\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"38\" y2=\"346\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"15\" y2=\"348\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-8\" y2=\"346\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-30\" y2=\"339\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-51\" y2=\"328\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-69\" y2=\"313\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-84\" y2=\"295\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-95\" y2=\"274\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-102\" y2=\"252\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-104\" y2=\"228\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-102\" y2=\"205\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-95\" y2=\"183\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-84\" y2=\"162\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-69\" y2=\"144\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-51\" y2=\"129\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-30\" y2=\"118\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"-8\" y2=\"111\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"15\" y2=\"108\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"38\" y2=\"111\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"60\" y2=\"118\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"81\" y2=\"129\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"99\" y2=\"144\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"114\" y2=\"162\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"125\" y2=\"183\" />\n",
       "\n",
       "  <line x1=\"15\" y1=\"228\" x2=\"132\" y2=\"205\" />\n",
       "\n",
       "  <circle cx=\"25\" cy=\"132\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"167\" cy=\"364\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"299\" cy=\"251\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"665\" cy=\"93\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"669\" cy=\"102\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"443\" cy=\"363\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"176\" cy=\"361\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"138\" cy=\"401\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"305\" cy=\"109\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"53\" cy=\"260\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"475\" cy=\"297\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"87\" cy=\"221\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"157\" cy=\"263\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"594\" cy=\"319\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"672\" cy=\"335\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"678\" cy=\"128\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"469\" cy=\"491\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"431\" cy=\"77\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"534\" cy=\"389\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"231\" cy=\"444\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"570\" cy=\"230\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"633\" cy=\"309\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"273\" cy=\"387\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"250\" cy=\"200\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"686\" cy=\"110\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"656\" cy=\"177\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"129\" cy=\"38\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"632\" cy=\"29\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"356\" cy=\"162\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"368\" cy=\"400\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"655\" cy=\"368\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"559\" cy=\"135\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"262\" cy=\"363\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"510\" cy=\"76\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"416\" cy=\"96\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"286\" cy=\"259\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"116\" cy=\"470\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"680\" cy=\"42\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"387\" cy=\"187\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"484\" cy=\"480\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"218\" cy=\"276\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"291\" cy=\"95\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"507\" cy=\"446\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"471\" cy=\"303\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"500\" cy=\"143\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"454\" cy=\"341\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"677\" cy=\"303\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"508\" cy=\"103\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"168\" cy=\"197\" r=\"10\"\n",
       "\n",
       "          style=fill:green; />\n",
       "\n",
       "  <circle cx=\"466\" cy=\"376\" r=\"10\"\n",
       "\n",
       "          style=fill:red; />\n",
       "\n",
       "  <circle cx=\"15\" cy=\"228\" r=\"10\"\n",
       "\n",
       "          style=fill:yellow; />\n",
       "\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<svg.Scene at 0x7f5a7704f128>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.__class__ = KarpathyGame\n",
    "np.set_printoptions(formatter={'float': (lambda x: '%.2f' % (x,))})\n",
    "x = g.observe()\n",
    "new_shape = (x[:-2].shape[0]//g.eye_observation_size, g.eye_observation_size)\n",
    "print(x[:-2].reshape(new_shape))\n",
    "print(x[-2:])\n",
    "g.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
